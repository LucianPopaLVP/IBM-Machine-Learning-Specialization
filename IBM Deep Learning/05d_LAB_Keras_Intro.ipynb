{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lucya\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=660bdbd169387550dc12e2269646f9a5e577300f24463aab4b651520eeed6d88\n",
      "  Stored in directory: c:\\users\\lucya\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lucya\\\\IBM-Machine-Learnin-Specialization\\\\IBM Deep Learning'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>178</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.415</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>10</td>\n",
       "      <td>179</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.200</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>3</td>\n",
       "      <td>139</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.402</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>7</td>\n",
       "      <td>187</td>\n",
       "      <td>68</td>\n",
       "      <td>39</td>\n",
       "      <td>304</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.254</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.141</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "718               1                     108              60              46   \n",
       "327              10                     179              70               0   \n",
       "242               3                     139              54               0   \n",
       "56                7                     187              68              39   \n",
       "729               2                      92              52               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "718      178  35.5              0.415   24             0  \n",
       "327        0  35.1              0.200   37             0  \n",
       "242        0  25.6              0.402   22             1  \n",
       "56       304  37.7              0.254   41             1  \n",
       "729        0  30.1              0.141   22             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.781\n",
      "roc-auc is 0.829\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6460 - accuracy: 0.6597 - val_loss: 0.6358 - val_accuracy: 0.6927\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6615 - val_loss: 0.6342 - val_accuracy: 0.6979\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.6632 - val_loss: 0.6328 - val_accuracy: 0.6927\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6649 - val_loss: 0.6315 - val_accuracy: 0.6927\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6684 - val_loss: 0.6302 - val_accuracy: 0.6979\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6649 - val_loss: 0.6291 - val_accuracy: 0.6875\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6684 - val_loss: 0.6280 - val_accuracy: 0.6823\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6701 - val_loss: 0.6270 - val_accuracy: 0.6771\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6736 - val_loss: 0.6261 - val_accuracy: 0.6771\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6326 - accuracy: 0.6684 - val_loss: 0.6252 - val_accuracy: 0.6771\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.6667 - val_loss: 0.6243 - val_accuracy: 0.6667\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6306 - accuracy: 0.6701 - val_loss: 0.6235 - val_accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6684 - val_loss: 0.6228 - val_accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6684 - val_loss: 0.6221 - val_accuracy: 0.6719\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6279 - accuracy: 0.6667 - val_loss: 0.6214 - val_accuracy: 0.6719\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.6667 - val_loss: 0.6207 - val_accuracy: 0.6719\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6615 - val_loss: 0.6201 - val_accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6254 - accuracy: 0.6615 - val_loss: 0.6195 - val_accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6632 - val_loss: 0.6189 - val_accuracy: 0.6719\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6632 - val_loss: 0.6183 - val_accuracy: 0.6719\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6632 - val_loss: 0.6177 - val_accuracy: 0.6719\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6649 - val_loss: 0.6172 - val_accuracy: 0.6719\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.6615 - val_loss: 0.6166 - val_accuracy: 0.6719\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.6597 - val_loss: 0.6161 - val_accuracy: 0.6719\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.6597 - val_loss: 0.6156 - val_accuracy: 0.6719\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6201 - accuracy: 0.6580 - val_loss: 0.6150 - val_accuracy: 0.6719\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6580 - val_loss: 0.6145 - val_accuracy: 0.6719\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6562 - val_loss: 0.6141 - val_accuracy: 0.6719\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6580 - val_loss: 0.6136 - val_accuracy: 0.6719\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6562 - val_loss: 0.6131 - val_accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6562 - val_loss: 0.6126 - val_accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.6562 - val_loss: 0.6121 - val_accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6562 - val_loss: 0.6117 - val_accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6562 - val_loss: 0.6112 - val_accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6562 - val_loss: 0.6107 - val_accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.6597 - val_loss: 0.6103 - val_accuracy: 0.6719\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6597 - val_loss: 0.6098 - val_accuracy: 0.6719\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.6597 - val_loss: 0.6094 - val_accuracy: 0.6719\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.6580 - val_loss: 0.6089 - val_accuracy: 0.6719\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.6580 - val_loss: 0.6085 - val_accuracy: 0.6719\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6580 - val_loss: 0.6080 - val_accuracy: 0.6719\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6115 - accuracy: 0.6597 - val_loss: 0.6076 - val_accuracy: 0.6719\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.6580 - val_loss: 0.6071 - val_accuracy: 0.6719\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6597 - val_loss: 0.6067 - val_accuracy: 0.6719\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6597 - val_loss: 0.6062 - val_accuracy: 0.6719\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6615 - val_loss: 0.6058 - val_accuracy: 0.6719\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.6615 - val_loss: 0.6054 - val_accuracy: 0.6719\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6615 - val_loss: 0.6049 - val_accuracy: 0.6719\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.6615 - val_loss: 0.6045 - val_accuracy: 0.6719\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.6615 - val_loss: 0.6041 - val_accuracy: 0.6719\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6072 - accuracy: 0.6615 - val_loss: 0.6036 - val_accuracy: 0.6719\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6615 - val_loss: 0.6032 - val_accuracy: 0.6719\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6615 - val_loss: 0.6028 - val_accuracy: 0.6719\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.6615 - val_loss: 0.6023 - val_accuracy: 0.6719\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6615 - val_loss: 0.6019 - val_accuracy: 0.6719\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6049 - accuracy: 0.6615 - val_loss: 0.6015 - val_accuracy: 0.6719\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6045 - accuracy: 0.6597 - val_loss: 0.6011 - val_accuracy: 0.6719\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6615 - val_loss: 0.6006 - val_accuracy: 0.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6035 - accuracy: 0.6649 - val_loss: 0.6002 - val_accuracy: 0.6719\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6649 - val_loss: 0.5998 - val_accuracy: 0.6719\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6649 - val_loss: 0.5994 - val_accuracy: 0.6719\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.6649 - val_loss: 0.5990 - val_accuracy: 0.6719\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.6649 - val_loss: 0.5985 - val_accuracy: 0.6719\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.6632 - val_loss: 0.5981 - val_accuracy: 0.6719\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6615 - val_loss: 0.5977 - val_accuracy: 0.6719\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6004 - accuracy: 0.6615 - val_loss: 0.5973 - val_accuracy: 0.6719\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6000 - accuracy: 0.6649 - val_loss: 0.5969 - val_accuracy: 0.6719\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5996 - accuracy: 0.6667 - val_loss: 0.5965 - val_accuracy: 0.6719\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.6667 - val_loss: 0.5960 - val_accuracy: 0.6719\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6667 - val_loss: 0.5956 - val_accuracy: 0.6719\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6667 - val_loss: 0.5952 - val_accuracy: 0.6719\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6667 - val_loss: 0.5948 - val_accuracy: 0.6771\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6667 - val_loss: 0.5944 - val_accuracy: 0.6771\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6684 - val_loss: 0.5940 - val_accuracy: 0.6771\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6684 - val_loss: 0.5936 - val_accuracy: 0.6771\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5961 - accuracy: 0.6684 - val_loss: 0.5932 - val_accuracy: 0.6771\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6684 - val_loss: 0.5928 - val_accuracy: 0.6771\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.6684 - val_loss: 0.5924 - val_accuracy: 0.6771\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6684 - val_loss: 0.5920 - val_accuracy: 0.6771\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.6684 - val_loss: 0.5916 - val_accuracy: 0.6771\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6684 - val_loss: 0.5912 - val_accuracy: 0.6771\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6684 - val_loss: 0.5908 - val_accuracy: 0.6771\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6684 - val_loss: 0.5904 - val_accuracy: 0.6771\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6684 - val_loss: 0.5900 - val_accuracy: 0.6771\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5924 - accuracy: 0.6684 - val_loss: 0.5896 - val_accuracy: 0.6771\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6684 - val_loss: 0.5892 - val_accuracy: 0.6771\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6684 - val_loss: 0.5888 - val_accuracy: 0.6771\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5912 - accuracy: 0.6684 - val_loss: 0.5884 - val_accuracy: 0.6771\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5907 - accuracy: 0.6684 - val_loss: 0.5880 - val_accuracy: 0.6771\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5904 - accuracy: 0.6684 - val_loss: 0.5876 - val_accuracy: 0.6771\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6684 - val_loss: 0.5872 - val_accuracy: 0.6771\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5895 - accuracy: 0.6701 - val_loss: 0.5868 - val_accuracy: 0.6771\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6753 - val_loss: 0.5864 - val_accuracy: 0.6771\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6753 - val_loss: 0.5861 - val_accuracy: 0.6771\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6771 - val_loss: 0.5857 - val_accuracy: 0.6771\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6771 - val_loss: 0.5853 - val_accuracy: 0.6823\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6771 - val_loss: 0.5849 - val_accuracy: 0.6875\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6771 - val_loss: 0.5845 - val_accuracy: 0.6927\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.6771 - val_loss: 0.5841 - val_accuracy: 0.6927\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6771 - val_loss: 0.5838 - val_accuracy: 0.6927\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6771 - val_loss: 0.5834 - val_accuracy: 0.6927\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.6771 - val_loss: 0.5830 - val_accuracy: 0.6979\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6771 - val_loss: 0.5826 - val_accuracy: 0.6979\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.6771 - val_loss: 0.5823 - val_accuracy: 0.6979\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.6771 - val_loss: 0.5819 - val_accuracy: 0.6979\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.6771 - val_loss: 0.5815 - val_accuracy: 0.6979\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6771 - val_loss: 0.5811 - val_accuracy: 0.6979\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6771 - val_loss: 0.5808 - val_accuracy: 0.6979\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6771 - val_loss: 0.5804 - val_accuracy: 0.6979\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6788 - val_loss: 0.5800 - val_accuracy: 0.6979\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.6771 - val_loss: 0.5797 - val_accuracy: 0.6979\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.6788 - val_loss: 0.5793 - val_accuracy: 0.6979\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.6788 - val_loss: 0.5789 - val_accuracy: 0.6979\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6788 - val_loss: 0.5786 - val_accuracy: 0.6979\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6788 - val_loss: 0.5782 - val_accuracy: 0.6979\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.6806 - val_loss: 0.5778 - val_accuracy: 0.6979\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.6788 - val_loss: 0.5775 - val_accuracy: 0.6979\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.6788 - val_loss: 0.5771 - val_accuracy: 0.6979\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.6771 - val_loss: 0.5767 - val_accuracy: 0.6979\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.6771 - val_loss: 0.5764 - val_accuracy: 0.6979\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6788 - val_loss: 0.5760 - val_accuracy: 0.6979\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.6788 - val_loss: 0.5757 - val_accuracy: 0.6979\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6788 - val_loss: 0.5753 - val_accuracy: 0.7031\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5772 - accuracy: 0.6788 - val_loss: 0.5750 - val_accuracy: 0.7031\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.6788 - val_loss: 0.5746 - val_accuracy: 0.7031\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.6788 - val_loss: 0.5743 - val_accuracy: 0.7031\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6788 - val_loss: 0.5739 - val_accuracy: 0.7031\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.6788 - val_loss: 0.5735 - val_accuracy: 0.7031\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5753 - accuracy: 0.6788 - val_loss: 0.5732 - val_accuracy: 0.7031\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.6806 - val_loss: 0.5728 - val_accuracy: 0.7031\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.6823 - val_loss: 0.5725 - val_accuracy: 0.7031\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.6806 - val_loss: 0.5722 - val_accuracy: 0.7031\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5739 - accuracy: 0.6840 - val_loss: 0.5718 - val_accuracy: 0.7031\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.6840 - val_loss: 0.5715 - val_accuracy: 0.7083\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.6840 - val_loss: 0.5711 - val_accuracy: 0.7083\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.6840 - val_loss: 0.5708 - val_accuracy: 0.7135\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.6840 - val_loss: 0.5704 - val_accuracy: 0.7188\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.6840 - val_loss: 0.5701 - val_accuracy: 0.7188\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.6823 - val_loss: 0.5698 - val_accuracy: 0.7188\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.6840 - val_loss: 0.5694 - val_accuracy: 0.7188\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.6840 - val_loss: 0.5691 - val_accuracy: 0.7188\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6823 - val_loss: 0.5687 - val_accuracy: 0.7188\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5703 - accuracy: 0.6858 - val_loss: 0.5684 - val_accuracy: 0.7188\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.6858 - val_loss: 0.5681 - val_accuracy: 0.7188\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.6858 - val_loss: 0.5677 - val_accuracy: 0.7188\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.6892 - val_loss: 0.5674 - val_accuracy: 0.7240\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.6892 - val_loss: 0.5671 - val_accuracy: 0.7240\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.6892 - val_loss: 0.5667 - val_accuracy: 0.7240\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.6910 - val_loss: 0.5664 - val_accuracy: 0.7240\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.6910 - val_loss: 0.5661 - val_accuracy: 0.7240\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.6910 - val_loss: 0.5658 - val_accuracy: 0.7240\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.6927 - val_loss: 0.5654 - val_accuracy: 0.7240\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.6944 - val_loss: 0.5651 - val_accuracy: 0.7292\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.6944 - val_loss: 0.5648 - val_accuracy: 0.7292\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.6927 - val_loss: 0.5645 - val_accuracy: 0.7292\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.6927 - val_loss: 0.5641 - val_accuracy: 0.7292\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.6927 - val_loss: 0.5638 - val_accuracy: 0.7292\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.6927 - val_loss: 0.5635 - val_accuracy: 0.7292\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.6927 - val_loss: 0.5632 - val_accuracy: 0.7292\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.6927 - val_loss: 0.5629 - val_accuracy: 0.7292\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.6927 - val_loss: 0.5625 - val_accuracy: 0.7292\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.6927 - val_loss: 0.5622 - val_accuracy: 0.7344\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.6927 - val_loss: 0.5619 - val_accuracy: 0.7344\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.6927 - val_loss: 0.5616 - val_accuracy: 0.7344\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.6927 - val_loss: 0.5613 - val_accuracy: 0.7344\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.6927 - val_loss: 0.5610 - val_accuracy: 0.7344\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.6927 - val_loss: 0.5607 - val_accuracy: 0.7396\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.6927 - val_loss: 0.5603 - val_accuracy: 0.7396\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.6927 - val_loss: 0.5600 - val_accuracy: 0.7396\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.6927 - val_loss: 0.5597 - val_accuracy: 0.7396\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.6927 - val_loss: 0.5594 - val_accuracy: 0.7396\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.6910 - val_loss: 0.5591 - val_accuracy: 0.7396\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.6910 - val_loss: 0.5588 - val_accuracy: 0.7448\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.6910 - val_loss: 0.5585 - val_accuracy: 0.7448\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.6910 - val_loss: 0.5582 - val_accuracy: 0.7448\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.6927 - val_loss: 0.5579 - val_accuracy: 0.7448\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.6927 - val_loss: 0.5576 - val_accuracy: 0.7448\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.6962 - val_loss: 0.5573 - val_accuracy: 0.7448\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.6962 - val_loss: 0.5570 - val_accuracy: 0.7448\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.6962 - val_loss: 0.5567 - val_accuracy: 0.7448\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.6962 - val_loss: 0.5564 - val_accuracy: 0.7448\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.6979 - val_loss: 0.5561 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.6979 - val_loss: 0.5558 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.6997 - val_loss: 0.5555 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.6997 - val_loss: 0.5552 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7014 - val_loss: 0.5549 - val_accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7014 - val_loss: 0.5546 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7014 - val_loss: 0.5543 - val_accuracy: 0.7552\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7014 - val_loss: 0.5540 - val_accuracy: 0.7552\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7031 - val_loss: 0.5537 - val_accuracy: 0.7552\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7031 - val_loss: 0.5535 - val_accuracy: 0.7552\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7014 - val_loss: 0.5532 - val_accuracy: 0.7552\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7014 - val_loss: 0.5529 - val_accuracy: 0.7552\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7014 - val_loss: 0.5526 - val_accuracy: 0.7552\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7014 - val_loss: 0.5523 - val_accuracy: 0.7552\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7014 - val_loss: 0.5520 - val_accuracy: 0.7552\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7049 - val_loss: 0.5517 - val_accuracy: 0.7552\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7031 - val_loss: 0.5515 - val_accuracy: 0.7552\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7083 - val_loss: 0.5512 - val_accuracy: 0.7552\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7083 - val_loss: 0.5509 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1600/2018128257.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#  One is a hard decision, the other is a probabilitistic score.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0my_pred_class_nn_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_pred_prob_nn_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_class_nn_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1600/1432541550.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Let's check out the outputs to get a feel for how keras apis work.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred_class_nn_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_class_nn_1' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_prob_nn_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1600/3070183076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred_prob_nn_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_prob_nn_1' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_class_nn_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1600/99902677.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Print model performance and plot the roc curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy is {:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_class_nn_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roc-auc is {:.3f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_prob_nn_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_roc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_prob_nn_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_class_nn_1' is not defined"
     ]
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b25b3c3e20>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7083 - val_loss: 0.5506 - val_accuracy: 0.7552\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7101 - val_loss: 0.5503 - val_accuracy: 0.7552\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7101 - val_loss: 0.5501 - val_accuracy: 0.7552\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7101 - val_loss: 0.5498 - val_accuracy: 0.7552\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7101 - val_loss: 0.5495 - val_accuracy: 0.7552\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7049 - val_loss: 0.5492 - val_accuracy: 0.7552\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7101 - val_loss: 0.5490 - val_accuracy: 0.7552\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7066 - val_loss: 0.5487 - val_accuracy: 0.7552\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7066 - val_loss: 0.5484 - val_accuracy: 0.7552\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7066 - val_loss: 0.5481 - val_accuracy: 0.7552\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7066 - val_loss: 0.5479 - val_accuracy: 0.7552\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7066 - val_loss: 0.5476 - val_accuracy: 0.7552\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7066 - val_loss: 0.5473 - val_accuracy: 0.7552\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7066 - val_loss: 0.5471 - val_accuracy: 0.7552\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7066 - val_loss: 0.5468 - val_accuracy: 0.7552\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7083 - val_loss: 0.5465 - val_accuracy: 0.7552\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7083 - val_loss: 0.5463 - val_accuracy: 0.7552\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7049 - val_loss: 0.5460 - val_accuracy: 0.7552\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7083 - val_loss: 0.5457 - val_accuracy: 0.7552\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7066 - val_loss: 0.5455 - val_accuracy: 0.7552\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7083 - val_loss: 0.5452 - val_accuracy: 0.7552\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7083 - val_loss: 0.5450 - val_accuracy: 0.7552\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7101 - val_loss: 0.5447 - val_accuracy: 0.7552\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7101 - val_loss: 0.5444 - val_accuracy: 0.7552\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7118 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7135 - val_loss: 0.5439 - val_accuracy: 0.7552\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7118 - val_loss: 0.5437 - val_accuracy: 0.7552\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7153 - val_loss: 0.5434 - val_accuracy: 0.7552\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7118 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7188 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7170 - val_loss: 0.5427 - val_accuracy: 0.7552\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7188 - val_loss: 0.5424 - val_accuracy: 0.7552\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7205 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7205 - val_loss: 0.5419 - val_accuracy: 0.7604\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7205 - val_loss: 0.5417 - val_accuracy: 0.7604\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7205 - val_loss: 0.5414 - val_accuracy: 0.7604\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7222 - val_loss: 0.5412 - val_accuracy: 0.7604\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7222 - val_loss: 0.5409 - val_accuracy: 0.7604\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7222 - val_loss: 0.5407 - val_accuracy: 0.7604\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7222 - val_loss: 0.5404 - val_accuracy: 0.7604\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7274 - val_loss: 0.5402 - val_accuracy: 0.7604\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7274 - val_loss: 0.5400 - val_accuracy: 0.7604\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7274 - val_loss: 0.5397 - val_accuracy: 0.7604\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7274 - val_loss: 0.5395 - val_accuracy: 0.7604\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7274 - val_loss: 0.5392 - val_accuracy: 0.7604\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7292 - val_loss: 0.5390 - val_accuracy: 0.7604\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7292 - val_loss: 0.5388 - val_accuracy: 0.7604\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7274 - val_loss: 0.5385 - val_accuracy: 0.7604\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7274 - val_loss: 0.5383 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7292 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7292 - val_loss: 0.5378 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7292 - val_loss: 0.5376 - val_accuracy: 0.7604\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7292 - val_loss: 0.5373 - val_accuracy: 0.7604\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7309 - val_loss: 0.5371 - val_accuracy: 0.7604\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7309 - val_loss: 0.5369 - val_accuracy: 0.7604\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7309 - val_loss: 0.5366 - val_accuracy: 0.7604\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7309 - val_loss: 0.5364 - val_accuracy: 0.7604\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7309 - val_loss: 0.5362 - val_accuracy: 0.7604\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7309 - val_loss: 0.5360 - val_accuracy: 0.7604\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7309 - val_loss: 0.5357 - val_accuracy: 0.7604\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7326 - val_loss: 0.5355 - val_accuracy: 0.7604\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7344 - val_loss: 0.5353 - val_accuracy: 0.7604\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7344 - val_loss: 0.5351 - val_accuracy: 0.7604\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7344 - val_loss: 0.5348 - val_accuracy: 0.7604\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7344 - val_loss: 0.5346 - val_accuracy: 0.7604\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7344 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7344 - val_loss: 0.5342 - val_accuracy: 0.7604\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7361 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7361 - val_loss: 0.5337 - val_accuracy: 0.7552\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7361 - val_loss: 0.5335 - val_accuracy: 0.7604\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7361 - val_loss: 0.5333 - val_accuracy: 0.7604\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7361 - val_loss: 0.5331 - val_accuracy: 0.7604\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7326 - val_loss: 0.5329 - val_accuracy: 0.7604\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7326 - val_loss: 0.5326 - val_accuracy: 0.7604\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7309 - val_loss: 0.5324 - val_accuracy: 0.7604\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7292 - val_loss: 0.5322 - val_accuracy: 0.7604\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7292 - val_loss: 0.5320 - val_accuracy: 0.7604\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7292 - val_loss: 0.5318 - val_accuracy: 0.7604\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7292 - val_loss: 0.5316 - val_accuracy: 0.7604\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7292 - val_loss: 0.5314 - val_accuracy: 0.7604\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7274 - val_loss: 0.5312 - val_accuracy: 0.7604\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7257 - val_loss: 0.5310 - val_accuracy: 0.7604\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7274 - val_loss: 0.5308 - val_accuracy: 0.7604\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7257 - val_loss: 0.5305 - val_accuracy: 0.7604\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7274 - val_loss: 0.5303 - val_accuracy: 0.7604\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7274 - val_loss: 0.5301 - val_accuracy: 0.7604\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.7292 - val_loss: 0.5299 - val_accuracy: 0.7656\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7292 - val_loss: 0.5297 - val_accuracy: 0.7656\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7292 - val_loss: 0.5295 - val_accuracy: 0.7656\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7292 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7292 - val_loss: 0.5291 - val_accuracy: 0.7604\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7309 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7274 - val_loss: 0.5287 - val_accuracy: 0.7604\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7292 - val_loss: 0.5285 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7292 - val_loss: 0.5283 - val_accuracy: 0.7604\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7292 - val_loss: 0.5281 - val_accuracy: 0.7604\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7309 - val_loss: 0.5279 - val_accuracy: 0.7604\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7309 - val_loss: 0.5277 - val_accuracy: 0.7604\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7309 - val_loss: 0.5275 - val_accuracy: 0.7604\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7309 - val_loss: 0.5273 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7309 - val_loss: 0.5271 - val_accuracy: 0.7604\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7309 - val_loss: 0.5269 - val_accuracy: 0.7604\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7309 - val_loss: 0.5268 - val_accuracy: 0.7604\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7309 - val_loss: 0.5266 - val_accuracy: 0.7604\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7309 - val_loss: 0.5264 - val_accuracy: 0.7604\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7326 - val_loss: 0.5262 - val_accuracy: 0.7604\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7344 - val_loss: 0.5260 - val_accuracy: 0.7604\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7378 - val_loss: 0.5258 - val_accuracy: 0.7604\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7378 - val_loss: 0.5256 - val_accuracy: 0.7604\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7378 - val_loss: 0.5254 - val_accuracy: 0.7604\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7378 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7396 - val_loss: 0.5251 - val_accuracy: 0.7708\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7396 - val_loss: 0.5249 - val_accuracy: 0.7760\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7396 - val_loss: 0.5247 - val_accuracy: 0.7760\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7396 - val_loss: 0.5245 - val_accuracy: 0.7760\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7413 - val_loss: 0.5243 - val_accuracy: 0.7760\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7413 - val_loss: 0.5241 - val_accuracy: 0.7760\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7413 - val_loss: 0.5240 - val_accuracy: 0.7760\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7413 - val_loss: 0.5238 - val_accuracy: 0.7760\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7413 - val_loss: 0.5236 - val_accuracy: 0.7760\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7431 - val_loss: 0.5234 - val_accuracy: 0.7812\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7413 - val_loss: 0.5232 - val_accuracy: 0.7812\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7431 - val_loss: 0.5231 - val_accuracy: 0.7812\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7431 - val_loss: 0.5229 - val_accuracy: 0.7812\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7448 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.7465 - val_loss: 0.5225 - val_accuracy: 0.7812\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7431 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7465 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7465 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.7465 - val_loss: 0.5219 - val_accuracy: 0.7812\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7465 - val_loss: 0.5217 - val_accuracy: 0.7812\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.7465 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7465 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7465 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7465 - val_loss: 0.5210 - val_accuracy: 0.7812\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7465 - val_loss: 0.5208 - val_accuracy: 0.7812\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.7465 - val_loss: 0.5207 - val_accuracy: 0.7812\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7465 - val_loss: 0.5205 - val_accuracy: 0.7812\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7465 - val_loss: 0.5203 - val_accuracy: 0.7812\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.7465 - val_loss: 0.5202 - val_accuracy: 0.7812\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7465 - val_loss: 0.5200 - val_accuracy: 0.7812\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7465 - val_loss: 0.5198 - val_accuracy: 0.7812\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.7465 - val_loss: 0.5197 - val_accuracy: 0.7812\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7465 - val_loss: 0.5195 - val_accuracy: 0.7812\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7465 - val_loss: 0.5194 - val_accuracy: 0.7812\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7465 - val_loss: 0.5192 - val_accuracy: 0.7812\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7465 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7465 - val_loss: 0.5189 - val_accuracy: 0.7812\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7465 - val_loss: 0.5187 - val_accuracy: 0.7812\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.7465 - val_loss: 0.5186 - val_accuracy: 0.7812\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7465 - val_loss: 0.5184 - val_accuracy: 0.7812\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7465 - val_loss: 0.5182 - val_accuracy: 0.7812\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.7465 - val_loss: 0.5181 - val_accuracy: 0.7812\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7483 - val_loss: 0.5179 - val_accuracy: 0.7812\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7483 - val_loss: 0.5178 - val_accuracy: 0.7812\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.7483 - val_loss: 0.5176 - val_accuracy: 0.7812\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7483 - val_loss: 0.5175 - val_accuracy: 0.7812\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7483 - val_loss: 0.5173 - val_accuracy: 0.7812\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7465 - val_loss: 0.5172 - val_accuracy: 0.7812\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7483 - val_loss: 0.5170 - val_accuracy: 0.7812\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7465 - val_loss: 0.5169 - val_accuracy: 0.7812\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7465 - val_loss: 0.5167 - val_accuracy: 0.7812\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7483 - val_loss: 0.5166 - val_accuracy: 0.7812\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7483 - val_loss: 0.5164 - val_accuracy: 0.7812\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7465 - val_loss: 0.5163 - val_accuracy: 0.7812\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7465 - val_loss: 0.5161 - val_accuracy: 0.7812\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7465 - val_loss: 0.5160 - val_accuracy: 0.7812\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.7465 - val_loss: 0.5158 - val_accuracy: 0.7760\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.7465 - val_loss: 0.5157 - val_accuracy: 0.7760\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7483 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7483 - val_loss: 0.5154 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7483 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7500 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7500 - val_loss: 0.5150 - val_accuracy: 0.7760\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7483 - val_loss: 0.5148 - val_accuracy: 0.7760\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7500 - val_loss: 0.5147 - val_accuracy: 0.7760\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7483 - val_loss: 0.5145 - val_accuracy: 0.7760\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7465 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7465 - val_loss: 0.5143 - val_accuracy: 0.7760\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7483 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7465 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.7465 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7465 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7465 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.7465 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7465 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7465 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7465 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.7483 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7483 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7483 - val_loss: 0.5126 - val_accuracy: 0.7708\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7483 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7483 - val_loss: 0.5124 - val_accuracy: 0.7708\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7483 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7500 - val_loss: 0.5121 - val_accuracy: 0.7708\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7483 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7500 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7500 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7500 - val_loss: 0.5116 - val_accuracy: 0.7708\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7500 - val_loss: 0.5115 - val_accuracy: 0.7708\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7500 - val_loss: 0.5113 - val_accuracy: 0.7708\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7500 - val_loss: 0.5112 - val_accuracy: 0.7708\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7535 - val_loss: 0.5111 - val_accuracy: 0.7708\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7517 - val_loss: 0.5110 - val_accuracy: 0.7708\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7535 - val_loss: 0.5108 - val_accuracy: 0.7708\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7517 - val_loss: 0.5107 - val_accuracy: 0.7708\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7517 - val_loss: 0.5106 - val_accuracy: 0.7708\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7535 - val_loss: 0.5105 - val_accuracy: 0.7708\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7535 - val_loss: 0.5103 - val_accuracy: 0.7708\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7552 - val_loss: 0.5102 - val_accuracy: 0.7708\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7569 - val_loss: 0.5101 - val_accuracy: 0.7708\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.5100 - val_accuracy: 0.7708\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7587 - val_loss: 0.5099 - val_accuracy: 0.7708\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7587 - val_loss: 0.5097 - val_accuracy: 0.7708\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7587 - val_loss: 0.5096 - val_accuracy: 0.7708\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7587 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7587 - val_loss: 0.5094 - val_accuracy: 0.7708\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7587 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7587 - val_loss: 0.5092 - val_accuracy: 0.7760\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7587 - val_loss: 0.5090 - val_accuracy: 0.7760\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7587 - val_loss: 0.5089 - val_accuracy: 0.7760\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7587 - val_loss: 0.5088 - val_accuracy: 0.7760\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7587 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7587 - val_loss: 0.5086 - val_accuracy: 0.7760\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7587 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7587 - val_loss: 0.5083 - val_accuracy: 0.7760\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7587 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7587 - val_loss: 0.5081 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7569 - val_loss: 0.5080 - val_accuracy: 0.7760\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7569 - val_loss: 0.5079 - val_accuracy: 0.7760\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7569 - val_loss: 0.5078 - val_accuracy: 0.7760\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7569 - val_loss: 0.5077 - val_accuracy: 0.7760\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7569 - val_loss: 0.5076 - val_accuracy: 0.7760\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7569 - val_loss: 0.5075 - val_accuracy: 0.7760\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7569 - val_loss: 0.5074 - val_accuracy: 0.7760\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7569 - val_loss: 0.5072 - val_accuracy: 0.7760\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7569 - val_loss: 0.5071 - val_accuracy: 0.7760\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7569 - val_loss: 0.5070 - val_accuracy: 0.7760\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7569 - val_loss: 0.5069 - val_accuracy: 0.7812\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.7587 - val_loss: 0.5068 - val_accuracy: 0.7812\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7587 - val_loss: 0.5067 - val_accuracy: 0.7812\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7587 - val_loss: 0.5066 - val_accuracy: 0.7812\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7587 - val_loss: 0.5065 - val_accuracy: 0.7812\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7587 - val_loss: 0.5064 - val_accuracy: 0.7812\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7587 - val_loss: 0.5063 - val_accuracy: 0.7812\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7587 - val_loss: 0.5062 - val_accuracy: 0.7812\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7587 - val_loss: 0.5061 - val_accuracy: 0.7865\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7587 - val_loss: 0.5060 - val_accuracy: 0.7812\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7587 - val_loss: 0.5059 - val_accuracy: 0.7812\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7587 - val_loss: 0.5058 - val_accuracy: 0.7812\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7587 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7587 - val_loss: 0.5056 - val_accuracy: 0.7760\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7587 - val_loss: 0.5055 - val_accuracy: 0.7760\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7587 - val_loss: 0.5054 - val_accuracy: 0.7760\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7587 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7587 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7587 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7587 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7587 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7587 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.7587 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7587 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7587 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7604 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7604 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7604 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7604 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7604 - val_loss: 0.5040 - val_accuracy: 0.7760\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7604 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7587 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7587 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7587 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7587 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7604 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7604 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7604 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7604 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7622 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7622 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7622 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7622 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.7622 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7622 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7622 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7622 - val_loss: 0.5025 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7622 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7622 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7622 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7622 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7622 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7622 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7622 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7622 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7622 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7622 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7622 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7622 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7622 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7622 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7622 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7622 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7622 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.7622 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7622 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7622 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7622 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7622 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7622 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7639 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7639 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7639 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7639 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7639 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7639 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.7639 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7639 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7639 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7639 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.7639 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7639 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7639 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7639 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7639 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7639 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7760\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7656 - val_loss: 0.4990 - val_accuracy: 0.7760\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7656 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7674 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7656 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7674 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7674 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7674 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7674 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7674 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7691 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7691 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7691 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7691 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7691 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7691 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7691 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7691 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7691 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7691 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7691 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7691 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7691 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7691 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7691 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7691 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7656\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7656\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7656\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4804 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7674 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7674 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7708 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7691 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7691 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7691 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7674 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7691 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7691 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7691 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7691 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7674 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7691 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7708 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7691 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7708 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7691 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7708 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7691 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7691 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7708 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7691 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7691 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.4910 - val_accuracy: 0.7708\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7674 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.4908 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7674 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7674 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7674 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7691 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7674 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7674 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7674 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7691 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7691 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7674 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7691 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7691 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7691 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7691 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7691 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7691 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.7691 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7691 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7708 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7691 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7708 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7691 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7708 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7691 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7691 - val_loss: 0.4899 - val_accuracy: 0.7708\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.7691 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7708 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7691 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7708 - val_loss: 0.4898 - val_accuracy: 0.7708\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7691 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7708 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7708 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4897 - val_accuracy: 0.7708\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4896 - val_accuracy: 0.7708\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7708 - val_loss: 0.4896 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7708 - val_loss: 0.4895 - val_accuracy: 0.7708\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7708 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7708\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7708 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7708 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7708 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7708 - val_loss: 0.4893 - val_accuracy: 0.7708\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7708 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7708 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7708\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7708 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7708\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7708\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4890 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7708 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7726 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7656\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7708 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7708 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7708 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7656\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7726 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7726 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7726 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7604\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7604\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7604\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4878 - val_accuracy: 0.7604\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7604\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4877 - val_accuracy: 0.7552\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7604\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7795 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4874 - val_accuracy: 0.7552\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7812 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4875 - val_accuracy: 0.7552\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7552\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4876 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b25b4154f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAHSCAYAAADseZbhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABaZUlEQVR4nO3deZhU5Z33//fd3SyKoAiopFERB43I0mAraUWBoBNjHAWXxCUicZSgj3GbCCZPEhm9EoU4E+OTKKPEJYkjY2JEjYpRxvUXYgSCC+CKqKCiICIuQC/374+qaqqb6u7qvar7/bquvqrq1DmnTuFR+fT3vr93iDEiSZIkSVKuKmjvC5AkSZIkqT4GV0mSJElSTjO4SpIkSZJymsFVkiRJkpTTDK6SJEmSpJxmcJUkSZIk5bSi9r6Axujbt28cOHBge1+GJEmSJKkVLFmyZH2MsV/t7XkVXAcOHMjixYvb+zIkSZIkSa0ghPBWpu0OFZYkSZIk5TSDqyRJkiQppxlcJUmSJEk5La/muEqSJElqH+Xl5axZs4YtW7a096WoA+jevTsDBgygS5cuWe1vcJUkSZLUoDVr1tCzZ08GDhxICKG9L0d5LMbIhg0bWLNmDfvtt19WxzhUWJIkSVKDtmzZQp8+fQytarYQAn369GlU9T6r4BpCODaE8EoI4fUQwhV17DMuhLAshLA8hPBk2vbVIYQXk+8tTtu+ewjh0RDCa8nH3llftSRJkqQ2Z2hVS2nsvdRgcA0hFAK/Br4ODAFODyEMqbXPbsCNwAkxxoOBU2udZnyMsSTGWJq27QpgYYxxMLAw+VqSJEmSdrBhwwZKSkooKSlhr732ori4uPr1tm3b6j128eLFXHTRRY36vIEDB7J+/frmXHKTrV69mp122omSkhKGDBnC5MmTKS8vb5Fz/9//+3/Ze++92WWXXVrkfG0lm4rrYcDrMcZVMcZtwDzgxFr7nAH8Kcb4NkCM8YMsznsicEfy+R3AxKyuWJIkSVKn06dPH5YtW8ayZcuYNm0al156afXrrl27UlFRUeexpaWl3HDDDW14tc23//77s2zZMl588UXWrFnD3Xff3SLn/Zd/+Rf+/ve/t8i52lI2wbUYeCft9ZrktnQHAL1DCE+EEJaEECanvReBvyS3T03bvmeM8T2A5OMemT48hDA1hLA4hLD4ww8/zOJyJUmSJOWERYvgmmsSj61gypQpXHbZZYwfP54ZM2bw97//ncMPP5yRI0dy+OGH88orrwDwxBNPcPzxxwMwc+ZMzjnnHMaNG8egQYMaFWjfeustJkyYwPDhw5kwYQJvv/02AH/4wx8YOnQoI0aM4KijjgJg+fLlHHbYYZSUlDB8+HBee+21Jn3HwsJCDjvsMNauXQvUrAQvXryYcePGNep7feUrX6F///5Nupb2lE1X4UyDj2OG8xwCTAB2AhaFEP4WY3wVOCLG+G4IYQ/g0RDCyzHGp7K9wBjjzcDNAKWlpbU/V5IkSVJbu+QSWLas/n02bYIXXoCqKigogOHDYddd696/pASuv77Rl/Lqq6/y2GOPUVhYyCeffMJTTz1FUVERjz32GD/84Q+55557djjm5Zdf5vHHH2fz5s0ceOCBnH/++Vkty3LhhRcyefJkzj77bG699VYuuugi5s+fz1VXXcUjjzxCcXExH3/8MQBz5szh4osv5swzz2Tbtm1UVlY2+rtBoinWs88+yy9/+csG923q98oH2VRc1wB7p70eALybYZ8FMcbPYozrgaeAEQAxxneTjx8A95IYegywLoTQHyD5mM3wYkmSJEn5YNOmRGiFxOOmTa3yMaeeeiqFhYXJj9zEqaeeytChQ7n00ktZvnx5xmO+8Y1v0K1bN/r27csee+zBunXrsvqsRYsWccYZZwBw1lln8cwzzwBwxBFHMGXKFG655ZbqgFpWVsbPfvYzZs2axVtvvcVOO+3UqO/1xhtvUFJSQp8+fdhnn30YPnx4g8c09Xvlg2wqrs8Bg0MI+wFrgdNIzGlNdx/wqxBCEdAVGA38IoTQAyiIMW5OPv9n4KrkMfcDZwPXJh/va+6XkSRJktQGsqmMLloEEybAtm3QtSvceSeUlbX4pfTo0aP6+Y9//GPGjx/Pvffey+rVq6uH0dbWrVu36ueFhYX1zo+tT6oz7pw5c3j22Wd58MEHKSkpYdmyZZxxxhmMHj2aBx98kK997WvMnTuXr371q9XH3nvvvfz7v/87AHPnzqW0tLTGuVNzXN977z3GjRvH/fffzwknnEBRURFVyV8I1F5OpqW+Vy5qsOIaY6wALgQeAVYCd8cYl4cQpoUQpiX3WQksAF4A/g7MjTG+BOwJPBNCeD65/cEY44Lkqa8FjgkhvAYck3wtSZIkqSMoK4OFC+HqqxOPrRBaa9u0aRPFxYl2PLfffnuLn//www9n3rx5ANx5552MGTMGSFRHR48ezVVXXUXfvn155513WLVqFYMGDeKiiy7ihBNO4IUXXqhxrkmTJlU3l6odWtP179+fa6+9lmuuuQZIzHFdsmQJQMZh0B1VVuu4xhgfijEeEGPcP8b40+S2OTHGOWn7/DzGOCTGODTGeH1y26oY44jkz8GpY5PvbYgxTogxDk4+ftTC302SJElSeyorgx/8oE1CK8D06dP5wQ9+wBFHHNHkOaXphg8fzoABAxgwYACXXXYZN9xwA7fddhvDhw/nd7/7XfW808svv5xhw4YxdOhQjjrqKEaMGMH//M//MHToUEpKSnj55ZeZPHlyA59Wt4kTJ/L555/z9NNPc+WVV3LxxRdz5JFHVg+Rbozp06czYMAAPv/8cwYMGMDMmTObfF1tKcSYP/2OSktL4+LFi9v7MiRJkqROZ+XKlRx00EHtfRnqQDLdUyGEJTHGHUrQ2cxxVbYWLIDnnoOjj26z3ypJkiRJUkeX1VBhZeHXv4avfx1mzkxMQm+ltaokSZIkqbMxuLaU5ILAVFUlOqc98US7Xo4kSZIkdRQG15Zy/PGJxxAS7b7raL0tSZIkSWocg2tLOfxwGDwYevVKrGvlHFdJkiRJahEG15ayaBG8+SZs2gSXXOIcV0mSJElqIQbXlvLEE5BaK8o5rpIkSVKL2rBhAyUlJZSUlLDXXntRXFxc/Xrbtm31Hrt48WIuuuiiRn3ewIEDWb9+fXMuuclWr17NTjvtRElJCUOGDGHy5MmUl5c3+7yff/453/jGN/jyl7/MwQcfzBVXXNECV9s2XA6npYwbl5jbunUrFBY6x1WSJElqQX369GHZsmUAzJw5k1122YXvf//71e9XVFRQVJQ53pSWllJausPSoDlt//33Z9myZVRWVnLMMcdw9913c+aZZzb7vN///vcZP34827ZtY8KECTz88MN8/etfb4Erbl1WXFtKWRncd1/i+ciR7XstkiRJUi5YtREWvJ54bAVTpkzhsssuY/z48cyYMYO///3vHH744YwcOZLDDz+cV155BYAnnniC45PNVGfOnMk555zDuHHjGDRoEDfccEPWn/fWW28xYcIEhg8fzoQJE3j77bcB+MMf/sDQoUMZMWIERx11FADLly/nsMMOo6SkhOHDh/Paa6816TsWFhZy2GGHsTa5ikl6JXjx4sWMSxbMsvleO++8M+PHjwega9eujBo1ijVr1jTputqaFdeW1KtXoqvws88m1nJduNAmTZIkSep4/rAc1nxS/z5flMPazRCBABT3hJ261L3/gF5w6sGNvpRXX32Vxx57jMLCQj755BOeeuopioqKeOyxx/jhD3/IPffcs8MxL7/8Mo8//jibN2/mwAMP5Pzzz6dLl3quLenCCy9k8uTJnH322dx6661cdNFFzJ8/n6uuuopHHnmE4uJiPv74YwDmzJnDxRdfzJlnnsm2bduoTE0rbKQtW7bw7LPP8stf/rLBfRvzvT7++GMeeOABLr744iZdV1uz4tqSnngCYkw8d56rJEmSOrMvKhKhFRKPX1S0yseceuqpFBYWArBp0yZOPfVUhg4dyqWXXsry5cszHvONb3yDbt260bdvX/bYYw/WrVuX1WctWrSIM844A4CzzjqLZ555BoAjjjiCKVOmcMstt1QH1LKyMn72s58xa9Ys3nrrLXbaaadGfa833niDkpIS+vTpwz777MPw4cMbPCbb71VRUcHpp5/ORRddxKBBgxp1Xe3FimtLGjcOunSB8vJE5bVPn/a+IkmSJKnlZVMZXbURfvk3qKyCwgL4zkgY1LvFL6VHjx7Vz3/84x8zfvx47r33XlavXl09jLa2bt26VT8vLCykoqJpoTqEACSqq88++ywPPvggJSUlLFu2jDPOOIPRo0fz4IMP8rWvfY25c+fy1a9+tfrYe++9l3//938HYO7cuTvMwU3NcX3vvfcYN24c999/PyeccAJFRUVUVVUBiWpsU77X1KlTGTx4MJdcckmTvnd7sOLaksrK4IILEs8rK10WR5IkSZ3XoN5w8Vfg+AMTj60QWmvbtGkTxcXFANx+++0tfv7DDz+cefPmAXDnnXcyZswYIFEdHT16NFdddRV9+/blnXfeYdWqVQwaNIiLLrqIE044gRdeeKHGuSZNmsSyZctYtmxZvY2j+vfvz7XXXss111wDJOa4LlmyBCDjMOiG/OhHP2LTpk1cf/31jT62PRlcW1rPnonHGB0uLEmSpM5tUG849p/aJLQCTJ8+nR/84AccccQRTZ5Tmm748OEMGDCAAQMGcNlll3HDDTdw2223MXz4cH73u99Vzzu9/PLLGTZsGEOHDuWoo45ixIgR/M///A9Dhw6lpKSEl19+mcmTJzf5OiZOnMjnn3/O008/zZVXXsnFF1/MkUceWT1EOltr1qzhpz/9KStWrGDUqFGUlJQwd+7cJl9XWwoxNSczD5SWlsbFixe392XUb9EiOPzwxPOuXRPB1QZNkiRJynMrV67koIMOau/LUAeS6Z4KISyJMe5Qgrbi2hoKkn+syTHvkiRJkqSmM7i2tPTOwhUVDhWWJEmSpGYyuLa0ceMSQ4RT7CwsSZIkSc1icG1pZWVw3XWJ53YWliRJkqRmM7i2hs2btz+3s7AkSZIkNYvBtTWMGwdFRYnnIThcWJIkSZKaweDaghYtgmuugUWUwXe+k9jocGFJkiSp2caNG8cjjzxSY9v111/PBRdcUO8xqeU0jzvuOD7++OMd9pk5cybXpab61WH+/PmsWLGi+vVPfvITHnvssUZcfWZPPPEExx9/fLPP01QzZ86kuLiYkpIShgwZwl133dUi592wYQPjx49nl1124cILL2yRcxpcW8j8+XDUUfDjH8OECbBoy8jEGzE6XFiSJElqptNPP5158+bV2DZv3jxOP/30rI5/6KGH2G233Zr02bWD61VXXcXRRx/dpHPlmksvvZRly5Zx33338d3vfpfy8vJmn7N79+5cffXVDf5CoDEMri1k4cLE6jeVlcmc2uO47W8WFiaGD0uSJEmdSPWIxBYYfHjKKafw5z//ma1btwKwevVq3n33XcaMGcP5559PaWkpBx98MFdeeWXG4wcOHMj69esB+OlPf8qBBx7I0UcfzSuvvFK9zy233MKhhx7KiBEjOPnkk/n888/561//yv3338/ll19OSUkJb7zxBlOmTOGPf/wjAAsXLmTkyJEMGzaMc845p/r6Bg4cyJVXXsmoUaMYNmwYL7/8ctbf9a677mLYsGEMHTqUGTNmAFBZWcmUKVMYOnQow4YN4xe/+AUAN9xwA0OGDGH48OGcdtppjfxT3W7w4MHsvPPObNy4cYdK8IUXXsjtt9+e9ffq0aMHY8aMoXv37k2+ntqKWuxMndw3vwm/+lViSmvXrjBu5CdQUABVVYmNkiRJUgdxySWwbFn9+2zaBC+8kPjrcEEBDB8Ou+5a9/4lJXD99XW/36dPHw477DAWLFjAiSeeyLx58/jWt75FCIGf/vSn7L777lRWVjJhwgReeOEFhg8fnvE8S5YsYd68efzjH/+goqKCUaNGccghhwBw0kkncd555wHwox/9iN/85jd873vf44QTTuD444/nlFNOqXGuLVu2MGXKFBYuXMgBBxzA5MmTuemmm7jkkksA6Nu3L0uXLuXGG2/kuuuuY+7cufX/oQHvvvsuM2bMYMmSJfTu3Zt//ud/Zv78+ey9996sXbuWl156CaB62PO1117Lm2++Sbdu3TIOhc7W0qVLGTx4MHvssUeN6nImTflezWXFtYUceSTsvz/06pX4F65sw5+3v7ltG/z2t+12bZIkSVJb27QpEVoh8bhpU/PPmT5cOH2Y8N13382oUaMYOXIky5cvrzd4Pf3000yaNImdd96ZXr16ccIJJ1S/99JLL3HkkUcybNgw7rzzTpYvX17v9bzyyivst99+HHDAAQCcffbZPPXUU9Xvn3TSSQAccsghrF69Oqvv+NxzzzFu3Dj69etHUVERZ555Jk899RSDBg1i1apVfO9732PBggX06tULgOHDh3PmmWfy+9//nqKixtclf/GLX3DggQcyevRoZs6cmdUxTflezWXFtYUsWgRvvZUYLnzJJTDs+uMpK5qZCK0xwm23weTJiXVeJUmSpDxWX2U0ZdGiRO+XbdsSIxLvvLP5fxWeOHEil112GUuXLuWLL75g1KhRvPnmm1x33XU899xz9O7dmylTprBly5Z6zxPqGBE5ZcoU5s+fz4gRI7j99tt5ooE+NTHGet/v1q0bAIWFhVRUVNS7b0Pn7N27N88//zyPPPIIv/71r7n77ru59dZbefDBB3nqqae4//77ufrqq1m+fHmNAPud73yHf/zjH3zpS1/ioYce2uG8l156Kd///vf505/+xOTJk3njjTcoKiqiKvVbB9jhz7Mp36u5rLi2kCee2P4bpW3b4IkNw+Ccc7bvUFFhgyZJkiR1GmVliT4wV1+deGyJ+s0uu+zCuHHjOOecc6qrrZ988gk9evRg1113Zd26dTz88MP1nuOoo47i3nvv5YsvvmDz5s088MAD1e9t3ryZ/v37U15ezp133lm9vWfPnmzevHmHc335y19m9erVvP766wD87ne/Y+zYsc36jqNHj+bJJ59k/fr1VFZWctdddzF27FjWr19PVVUVJ598MldffTVLly6lqqqKd955h/HjxzN79mw+/vhjPv300xrnu+2221i2bFnG0JrupJNOorS0lDvuuIN9992XFStWsHXrVjZt2sTChQub9Z1aghXXFjJuXOI3SVu2JAqsffoA4ybD3LmJ0Op6rpIkSepkyspafsDh6aefzkknnVQ9ZHjEiBGMHDmSgw8+mEGDBnHEEUfUe/yoUaP41re+RUlJCfvuuy9HHnlk9XtXX301o0ePZt9992XYsGHVYfW0007jvPPO44YbbqhuygSJ7rm33XYbp556KhUVFRx66KFMmzatUd9n4cKFDBgwoPr1H/7wB6655hrGjx9PjJHjjjuOE088keeff57vfOc71ZXQa665hsrKSr797W+zadMmYoxceumlTe6cDIllfs444wzOO+88vvnNbzJ8+HAGDx7MyJEjG32ugQMH8sknn7Bt2zbmz5/PX/7yF4YMGdLkawsNlbdzSWlpaUytw5SLbr4ZvvvdxPOddkr+Zmn+DJg9OxFcu3dvuV83SZIkSW1o5cqVHHTQQe19GepAMt1TIYQlMcbS2vs6VLgFbdiw/fmWLcl+TMlJ08QIW7c6XFiSJEmSGsng2oLGjUss2Qrb+zEt+uTg7TtUVTlcWJIkSZIayeDagsrKIH1pp4oKeGLZbtvXcQ0B/vGPdrk2SZIkScpXBtcWdtFF258XFsK4k/tAly6JDdVl2EXtc3GSJEmSlIcMri0sBCgo2P6cYbWWxdm2LTn5VZIkSZKUDYNrC3viiURhFdIy6uTJkFoE2KqrJEmSJDWKwbWFjRuXYWQwZXDWWdt3Ki+3u7AkSZLUCOPGjeORRx6pse3666/nggsuqPeY1HKaxx13HB9//PEO+8ycOZPrrruu3s+eP38+K1asqH79k5/8hMcee6wRV5/ZE088wfHHH9/s8zTVzJkzKS4upqSkhCFDhnDXXXe1yHkfffRRDjnkEIYNG8YhhxzC//7v/zb7nAbXFlZWVnNkcEVFMqN+5SvbN9pdWJIkSWqU008/nXnz5tXYNm/ePE4//fSsjn/ooYfYbbfdmvTZtYPrVVddxdFHH92kc+WaSy+9lGXLlnHffffx3e9+l/Ly8mafs2/fvjzwwAO8+OKL3HHHHZyVXsRrIoNrK0gfGRxCMqNu2GB3YUmSJHUqaz+rYtH7laz9rKrZ5zrllFP485//zNatWwFYvXo17777LmPGjOH888+ntLSUgw8+mCuvvDLj8QMHDmT9+vUA/PSnP+XAAw/k6KOP5pVXXqne55ZbbuHQQw9lxIgRnHzyyXz++ef89a9/5f777+fyyy+npKSEN954gylTpvDHP/4RgIULFzJy5EiGDRvGOeecU319AwcO5Morr2TUqFEMGzaMl19+OevvetdddzFs2DCGDh3KjBkzAKisrGTKlCkMHTqUYcOG8Ytf/AKAG264gSFDhjB8+HBOO+20Rv6pbjd48GB23nlnNm7cuEMl+MILL+T222/P+nuNHDmSL33pSwAcfPDBbNmypfrPpamKmnW0Miorg8sug9mzobISLrkEhl1/PGVdZiYmvqbGEE+enNhZkiRJyiOPralk3Rex3n22VkY+/AIiEN6DfjtV0q0w1Ln/njsFjh5QWOf7ffr04bDDDmPBggWceOKJzJs3j29961uEEPjpT3/K7rvvTmVlJRMmTOCFF15g+PDhGc+zZMkS5s2bxz/+8Q8qKioYNWoUhxxyCAAnnXQS5513HgA/+tGP+M1vfsP3vvc9TjjhBI4//nhOSV/7EtiyZQtTpkxh4cKFHHDAAUyePJmbbrqJSy65BEhUHpcuXcqNN97Iddddx9y5c+v9MwN49913mTFjBkuWLKF379788z//M/Pnz2fvvfdm7dq1vPTSSwDVw56vvfZa3nzzTbp165ZxKHS2li5dyuDBg9ljjz1qVJczacz3uueeexg5ciTdunVr8rWBFddW06tX4jFG2LoVnthgd2FJkiR1HlsrE6EVEo9bK5t/zvThwunDhO+++25GjRrFyJEjWb58eb3B6+mnn2bSpEnsvPPO9OrVixNOOKH6vZdeeokjjzySYcOGceedd7J8+fJ6r+eVV15hv/3244ADDgDg7LPP5qmnnqp+/6STTgLgkEMOYfXq1Vl9x+eee45x48bRr18/ioqKOPPMM3nqqacYNGgQq1at4nvf+x4LFiygVzJwDB8+nDPPPJPf//73FBU1vi75i1/8ggMPPJDRo0czc+bMrI7J9nstX76cGTNm8F//9V+Nvq7arLi2kn79tj+vntI6bjL85jeJ5kwxJp5bdZUkSVKeqa8ymrL2syrueq2SygiFAU4YWEhxj+bVzSZOnMhll13G0qVL+eKLLxg1ahRvvvkm1113Hc899xy9e/dmypQpbNmypd7zhJC58jtlyhTmz5/PiBEjuP3223migYaqMdZfdU5VGQsLC6moqKh334bO2bt3b55//nkeeeQRfv3rX3P33Xdz66238uCDD/LUU09x//33c/XVV7N8+fIaAfY73/kO//jHP/jSl77EQw89tMN5L730Ur7//e/zpz/9icmTJ/PGG29QVFREVdX24d21/zyz+V5r1qxh0qRJ/Pa3v2X//ffP6rvXJ6s7J4RwbAjhlRDC6yGEK+rYZ1wIYVkIYXkI4cnktr1DCI+HEFYmt1+ctv/MEMLa5DHLQgjHNfvb5JD0Ka2QnNJaVgbf+Mb2jeXlVl0lSZLUIRX3KOD0wYUc1T/x2NzQCrDLLrswbtw4zjnnnOpq6yeffEKPHj3YddddWbduHQ8//HC95zjqqKO49957+eKLL9i8eTMPPPBA9XubN2+mf//+lJeXc+edd1Zv79mzJ5s3b97hXF/+8pdZvXo1r7/+OgC/+93vGDt2bLO+4+jRo3nyySdZv349lZWV3HXXXYwdO5b169dTVVXFySefzNVXX83SpUupqqrinXfeYfz48cyePZuPP/6YTz/9tMb5brvtNpYtW5YxtKY76aSTKC0t5Y477mDfffdlxYoVbN26lU2bNrFw4cJGfYePP/6Yb3zjG1xzzTUcccQRjf4zyKTBimsIoRD4NXAMsAZ4LoRwf4xxRdo+uwE3AsfGGN8OIeyRfKsC+LcY49IQQk9gSQjh0bRjfxFjrL/3dJ5KLYuzbVvidfWU1r32qrnj+++3+bVJkiRJbaG4RwHFPVr2nKeffjonnXRS9ZDhESNGMHLkSA4++GAGDRrUYFAaNWoU3/rWtygpKWHfffflyCOPrH7v6quvZvTo0ey7774MGzasOqyedtppnHfeedxwww3VTZkAunfvzm233capp55KRUUFhx56KNOmTWvU91m4cCEDBgyofv2HP/yBa665hvHjxxNj5LjjjuPEE0/k+eef5zvf+U51JfSaa66hsrKSb3/722zatIkYI5deemmTOydDYpmfM844g/POO49vfvObDB8+nMGDBzNy5MhGnedXv/oVr7/+OldffTVXX301AH/5y1/YY489GjiybqGh8nYIoQyYGWP8WvL1DwBijNek7XMB8KUY448aONd9wK9ijI+GEGYCnzYmuJaWlsbUOkz54PzzYc6cxPMQ4LvfhZsmL4KxYxPVVoBu3eDxxx0uLEmSpJy2cuVKDjrooPa+DHUgme6pEMKSGGNp7X2zqdcXA++kvV6T3JbuAKB3COGJEMKSEMLk2icJIQwERgLPpm2+MITwQgjh1hBC7yyuJa9MnpyousL2Ka2LKIN//dftO9mkSZIkSZLqlU1wzTRzuXaZtgg4BPgG8DXgxyGEA6pPEMIuwD3AJTHGT5KbbwL2B0qA94D/yPjhIUwNISwOISz+8MMPs7jc3FFWBselzdytntI6eTJ07ZrYWJ1oF7XLNUqSJElSrssmuK4B9k57PQB4N8M+C2KMn8UY1wNPASMAQghdSITWO2OMf0odEGNcF2OsjDFWAbcAh2X68BjjzTHG0hhjab/0Vr15on//mq/ff596Eq0kSZIkqbZsgutzwOAQwn4hhK7AacD9tfa5DzgyhFAUQtgZGA2sDIk+078BVsYY/zP9gBBCeqSbBLzU1C+Ry9KHCwM8/HCyuGqTJkmSJOWZhvrjSNlq7L3UYHCNMVYAFwKPACuBu2OMy0MI00II05L7rAQWAC8AfwfmxhhfAo4AzgK+mmHZm9khhBdDCC8A44FLG3XleaKsrimttRPtAw/AzTe3+fVJkiRJ2ejevTsbNmwwvKrZYoxs2LCB7t27Z31Mg12Fc0m+dRVOWVSrkXCXLvDkk1D227S2wwCFhfD003YYliRJUs4pLy9nzZo1bNmypb0vRR1A9+7dGTBgAF3Si3nU3VW4wXVc1XypKa333Zd4nZrSWjZ5MtxyC1RWJt6orEy+YXCVJElSbunSpQv77bdfe1+GOqls5riqBdTZpOlf/iXDG5IkSZKkFINrG6lzSuv06c51lSRJkqR6GFzbSO0mTZWVcMEFsIi63nBdV0mSJEkCg2ubmjw50X8pJTWlte43JEmSJEkG1zZU55RW57pKkiRJUp0Mrm2szimtznWVJEmSpIwMrm3Mua6SJEmS1DgG13aQaUrr7Nn1vSFJkiRJnZfBtR1kmtL6wAPJqmvtN+67zyHDkiRJkjo1g2s7mT69ZnG1qirZSLj2GzHChRc6ZFiSJElSp2VwbSdlZXDjjdszaozwm98kq6433ggFaf9oKipcHkeSJElSp2VwbUdTp9YcGVxenpzSOnUq3HQThJB4ozrVWnWVJEmS1PkYXNvZXnvVfF09pXXqVDjhhO1vVKdaSZIkSepcDK7trHYj4RjTVsHp37/mzjZqkiRJktQJGVzbWWqua2pUMNSzPE6NVCtJkiRJnYPBNQdMnQonnlhz2333wc0v1pdqJUmSJKlzMLjmiEyr4FxwASwaVleqdciwJEmSpM7B4Joj6h0yXGeqdciwJEmSpI7P4JpDHDIsSZIkSTsyuOaYTMXV88+Hm3HIsCRJkqTOyeCaY1JDhgvS/slUVSVHBn/9KocMS5IkSep0DK45aOpUuOmmDCODHx6WSLXpKivht79t2wuUJEmSpDZkcM1Rdc53ZSpMnFjzjfffb7PrkiRJkqS2ZnDNYXU2E/76VdCly/Y3HnjAua6SJEmSOiyDaw6rc4mch4fBv/5rzY3OdZUkSZLUQRlcc1ydQ4Z7fb9mOdblcSRJkiR1UAbXPJBxyPB/7M+iI75fc0eXx5EkSZLUARlc80CdQ4b5vsvjSJIkSerwDK55IuOQ4af7cvNpCzMkWocMS5IkSeo4DK55JOOQ4XljWXTk9Jo7OmRYkiRJUgdicM0jDhmWJEmS1BkZXPNMo4YMn3uu4VWSJElS3jO45qFMQ4an/fdYbh7xq5o7rlgBY8caXiVJkiTlNYNrHso0ZDhGmPb8NG4OU2vuXF5usyZJkiRJec3gmqcyDRmOsYALuJFFlNV8w2ZNkiRJkvKYwTWPTZ8OXbrU3FYZC5ldcueO5VibNUmSJEnKUwbXPFZWBk8+CUOG1Nx+3/P7cfMZj7u+qyRJkqQOweCa58rKYO5c13eVJEmS1HEZXDsA13eVJEmS1JEZXDuIRq3v6pBhSZIkSXnE4NqBZFrf1SHDkiRJkvKdwbUDadSQ4fPPN7xKkiRJygsG1w4m05Dh+U/1ZcaE56Ag7R93VZXzXSVJkiTlhayCawjh2BDCKyGE10MIV9Sxz7gQwrIQwvIQwpMNHRtC2D2E8GgI4bXkY+/mfx3BjkOGAWb/ZSQzjl7sfFdJkiRJeafB4BpCKAR+DXwdGAKcHkIYUmuf3YAbgRNijAcDp2Zx7BXAwhjjYGBh8rVaQKYhwwA/f3QkN4/4Vc2NzneVJEmSlOOyqbgeBrweY1wVY9wGzANqDUblDOBPMca3AWKMH2Rx7InAHcnndwATm/wttIOpU+Hyy2tuixEueGEaiwqOqLXRIcOSJEmSclc2wbUYeCft9ZrktnQHAL1DCE+EEJaEECZnceyeMcb3AJKPezT24lW/WbMSw4bTVVYVMHv47xwyLEmSJClvZBNcQ4ZtsdbrIuAQ4BvA14AfhxAOyPLY+j88hKkhhMUhhMUffvhhYw4VifA6cWLNbfc9v9+OQ4bnz4cZM9rqsiRJkiQpa9kE1zXA3mmvBwDvZthnQYzxsxjjeuApYEQDx64LIfQHSD5+QAYxxptjjKUxxtJ+/fplcbmqLdP6ruc/P42bw9SaO86ebXiVJEmSlHOyCa7PAYNDCPuFELoCpwH319rnPuDIEEJRCGFnYDSwsoFj7wfOTj4/O3kOtYJUs6Yaq+HEAi7gRhZRVnPnn//cZk2SJEmSckqDwTXGWAFcCDxCIozeHWNcHkKYFkKYltxnJbAAeAH4OzA3xvhSXccmT30tcEwI4TXgmORrtZKpU+Gmm2pNbY2FnNvnTyziK9s32qxJkiRJUo4JMTZqymm7Ki0tjYsXL27vy8hrkyYlprOm61JQwZNVR1LG37ZvnDgR7r23LS9NkiRJUicXQlgSYyytvT2bocLqQGrPdwUorypi9l7/WXOj67tKkiRJyhEG104mNd811Or3fN+6r9Rs1uSQYUmSJEk5wuDaCU2dCnPm1AyvMYYdmzW5vqskSZKkHGBw7aQyhdfKWMjsvf6j5o4OGZYkSZLUzgyundjUqXDiiTW3ZRwyPG2a4VWSJElSuzG4dnK1mzXFGJgWb+JmzkvfaHiVJEmS1G4Mrp1cpmZNkQKmMYebOTdto82aJEmSJLUPg6syDhmOpJo1fWX7Rps1SZIkSWoHBlcBiSHDXbqkbwlUUsTsnlfV3NFmTZIkSZLamMFVQGLI8JNPwpAh6VsD9316tOu7SpIkSWpXBldVKyuDuXOzaNZUWQnnnmt4lSRJktQmDK6qIetmTStWwNixhldJkiRJrc7gqh1k3aypvNxmTZIkSZJancFVGdXZrInLa+5osyZJkiRJrczgqozqbNYUJtac72qzJkmSJEmtzOCqOmVu1lTABeEmFlG2faPru0qSJElqRQZX1StTs6bKWMi5u9xVc77r/PkwY0abX58kSZKkjs/gqgZlata04tN9GMsTNcPr7NmGV0mSJEktzuCqrEyfXnPIMATK6bpjs6af/9xmTZIkSZJalMFVWck0ZBgC9zGx5vquMcL55xteJUmSJLUYg6uyNnUqzJlTM7xGCpjGf9XsNFxVZadhSZIkSS3G4KpGqTO8hjk1w6udhiVJkiS1EIOrGi1Ts6YYC7iAG+00LEmSJKnFGVzVJNOnQ5cuNbdVUshsptfcaKdhSZIkSc1kcFWTlJXBk0/CkCHpWwP3hRNrDhkGOw1LkiRJahaDq5qsrAzmzq25TE6MBUxjDjP4WfpGmzVJkiRJajKDq5oltUxOQdqdFClgNlfUDK+VlXDuuYZXSZIkSY1mcFWzTZ0KN9204xqvP2dGzTVeV6yAsWMNr5IkSZIaxeCqFjF1Klx+ec1tkbBjp+HycpfJkSRJktQoBle1mFmzEt2GtwtUUsS53FIzvN53n82aJEmSJGXN4KoWNWsWTJyYviWwgoMZyxPbw6vNmiRJkiQ1gsFVLW769JqdhiFQTldmkzaW2GZNkiRJkrJkcFWLS3Uart2s6T4m2qxJkiRJUqMZXNUqpk6FOXNqhtdIYBpzaoZXmzVJkiRJaoDBVa1mx/AaiBTsGF5t1iRJkiSpHgZXtaqpU+HEE9O3JMJrjWVyYoRp0wyvkiRJkjIyuKrVTZ8OXbqkb8mwTI7hVZIkSVIdDK5qdWVl8OSTMGRI+laXyZEkSZKUHYOr2kRZGcydm+UyOTZrkiRJkpTG4Ko2k3mZHJjPRGbws7QN82HGjDa9NkmSJEm5q6i9L0Cdy9Spicdp0xIjgyGRYmdzBQCz+GFih1TVddastr1ASZIkSTnHiqvaXKZlcgB+zoyay+T8/Oc2a5IkSZJkcFX7mDoVLr88fUsgElwmR5IkSdIODK5qN7NmJZbK2c5lciRJkiTtKKvgGkI4NoTwSgjh9RDCFRneHxdC2BRCWJb8+Uly+4Fp25aFED4JIVySfG9mCGFt2nvHteg3U16YNQsmTkzfUscyOeefb3iVJEmSOqkGg2sIoRD4NfB1YAhweghhSIZdn44xliR/rgKIMb6S2gYcAnwO3Jt2zC/SjnmouV9G+Wn69CyWyamqco1XSZIkqZPKpuJ6GPB6jHFVjHEbMA84sQmfNQF4I8b4VhOOVQeW9TI5lZVw7rmGV0mSJKmTySa4FgPvpL1ek9xWW1kI4fkQwsMhhIMzvH8acFetbReGEF4IIdwaQuid6cNDCFNDCItDCIs//PDDLC5X+Shzp+ECZnNFzfC6YgWMHWt4lSRJkjqRbIJryLAt1nq9FNg3xjgC+H/A/BonCKErcALwh7TNNwH7AyXAe8B/ZPrwGOPNMcbSGGNpv379srhc5asdw2vCDsvklJdvX+dVkiRJUoeXTXBdA+yd9noA8G76DjHGT2KMnyafPwR0CSH0Tdvl68DSGOO6tGPWxRgrY4xVwC0khiSrk6trmZxpzKlZeZ0/H2bMaOOrkyRJktQesgmuzwGDQwj7JSunpwH3p+8QQtgrhESdLIRwWPK8G9J2OZ1aw4RDCP3TXk4CXmr85asjSi2Tkz5sOGYaNjx7tuFVkiRJ6gSKGtohxlgRQrgQeAQoBG6NMS4PIUxLvj8HOAU4P4RQAXwBnBZjjAAhhJ2BY4Dv1jr17BBCCYlhx6szvK9ObNYs2H//xBKuyTsJiMwmEVRn8cPEjj//eWLHqVPb61IlSZIktbKQzJd5obS0NC5evLi9L0NtaMaM2tNZE/frdK7dHl5DSEyONbxKkiRJeS2EsCTGWFp7ezZDhaV2kxo2vF1i/HCNhk0xJkqzN9/c5tcnSZIkqfUZXJXzMoXXVMOmGuH1ggtcJkeSJEnqgAyuyguZw2tBzfBaWQnnnmt4lSRJkjoYg6vyxqxZMHFi+pZEeL2AG1nEVxKbVqyAsWMNr5IkSVIHYnBVXpk+Hbp0Sd8SqKSIc7lle3gtL6/d0UmSJElSHjO4Kq+UlcGTT8KQITW3r+BgxvLE9vA6f75rvEqSJEkdhMFVeaesDObOhcLC1JYABMrpWrPyOnu24VWSJEnqAAyuyktlZXDjjYklXNPtUHn9+c9dJkeSJEnKcwZX5a2pU2HOnPTwmqHy6hqvkiRJUt4zuCqv7RheE2pUXg2vkiRJUl4zuCrv1Vd5nc3liU2GV0mSJClvGVzVIdRVeZ3PRGbws8QLw6skSZKUlwyu6jDqqrzO5oqa4fWCC2DRona6SkmSJEmNZXBVh5I5vMJsZmwPr5WVcO65hldJkiQpTxhc1eFMnQqXX56+JUPldcUKGDvW8CpJkiTlAYOrOqRZs2D69PQtGSqv5eVWXiVJkqQ8YHBVh5U5vGaovB55pA2bJEmSpBxmcFWHllXltbLShk2SJElSDjO4qsPLqvJqwyZJkiQpZxlc1SnUV3mdxD0s4is2bJIkSZJylMFVnUZdldf5TGIsTyTCqw2bJEmSpJxjcFWnkgqvNdd5DZTTlXO5xcqrJEmSlIMMrup0Zs2COXPSw2vCCg6uWXmdPbt9LlCSJElSDQZXdUpTp9YOrxkqr/Pnw4wZ7XeRkiRJkgCDqzqxHcNrQo3K6+zZhldJkiSpnRlc1allVXk1vEqSJEntyuCqTs/KqyRJkpTbDK4SVl4lSZKkXGZwlZKsvEqSJEm5yeAqpbHyKkmSJOUeg6tUS32V1zE8zc2ca3iVJEmS2lBRe1+AlIumTk08TpsGMUKi8gpVFDKNOYl9Zs9O7DRrVttfoCRJktSJGFylOuwYXgECkQLDqyRJktSGDK5SPVLh9fzzoaoKIGJ4lSRJktqWc1ylBkydCs88A0OGQGrIcHp4dc6rJEmS1LoMrlIWyspg7lzo0iW1ZXvl9bv8FzP4meFVkiRJaiUGVylLZWXw5JM7Vl4hMJsrDK+SJElSKzG4So1QV+UVYDYztofXSZNg0aL2ukxJkiSpQzG4So2UqrwedRQkQmsqvKZVXufPh7FjDa+SJElSCzC4Sk2QCq/Tp0PN8JqovE7iHhaVHwLnnmt4lSRJkprJ4Co1w6xZmcJrYD6TGMPT3LzicCuvkiRJUjMZXKVmSoXXEGqG1yoKE8vllJ9t5VWSJElqBoOr1AJmzYI5c9LDK9RY69XKqyRJktRkWQXXEMKxIYRXQgivhxCuyPD+uBDCphDCsuTPT9LeWx1CeDG5fXHa9t1DCI+GEF5LPvZuma8ktY+pUxPhtaAgFV5rrfXa/yH47VJYtbGdr1SSJEnKLw0G1xBCIfBr4OvAEOD0EMKQDLs+HWMsSf5cVeu98cntpWnbrgAWxhgHAwuTr6W8NnUqPPMMDBkS0rYG9jsk8sqZY/nPg09h7e+WwzNvt9s1SpIkSfkmm4rrYcDrMcZVMcZtwDzgxBb47BOBO5LP7wAmtsA5pXa3fa3XROV135GVnDunitGnwNbDe3PncaWsXfi24VWSJEnKUjbBtRh4J+31muS22spCCM+HEB4OIRyctj0CfwkhLAkhTE3bvmeM8T2A5OMejbx2KWdtX+s1sN/ICAFCSMyBrSos4KExQ1j7mOFVkiRJykY2wTVk2BZrvV4K7BtjHAH8P2B+2ntHxBhHkRhq/H9CCEc15gJDCFNDCItDCIs//PDDxhwqtatUeD3lqwUQY+InaUPvXfj98YeybOlHhldJkiSpAdkE1zXA3mmvBwDvpu8QY/wkxvhp8vlDQJcQQt/k63eTjx8A95IYegywLoTQHyD5+EGmD48x3hxjLI0xlvbr1y/rLybliv9zZgHHDSxMLvUaU6VXYkFgwREHsWyJ4VWSJEmqTzbB9TlgcAhhvxBCV+A04P70HUIIe4XEOiCEEA5LnndDCKFHCKFncnsP4J+Bl5KH3Q+cnXx+NnBfc7+MlKtK+hZy7N5p4RWqA+yCMcnweu/Kdr1GSZIkKVc1GFxjjBXAhcAjwErg7hjj8hDCtBDCtORupwAvhRCeB24ATosxRmBP4Jnk9r8DD8YYFySPuRY4JoTwGnBM8rXUYe0QXtOqrwvGHMTjGwsMr5IkSVIGIcba01VzV2lpaVy8eHHDO0o5bO1nVTz02jY2VBUkgitUV2EHvLeR8eFzio/brx2vUJIkSWofIYQltZZRBbIbKiypBRX3KOC4wV0pqF15Bdb0783v9/gSyx5d274XKUmSJOUQg6vUDop7FHDmAUUM6JFWcU1v2rR7X8OrJEmSlGRwldpJcY8Cvn1gF0bvmfzXsHbTpt37suyuV2HVxva7SEmSJCkHGFyldja+uIhj9ylMvKjdtOmAfXn8qQ8Nr5IkSerUDK5SDijpW8hZBxbRp3zb9o3J8Prs8IH8/o1K1r66qf0uUJIkSWpHBlcpRxT3KOC4oTtTkKq6pjdt6tOL32/uzrK/fdjOVylJkiS1PYOrlEOKexRw5pe7MKAyWXlNb9oUAgu69DK8SpIkqdMxuEo5prhHAd8+dBdGl38KkR2bNnXpxeOPr2vXa5QkSZLaksFVylHjR+/OseWbtg8bTqu+Prtrb37/vxuc9ypJkqROweAq5bCSr/TjrJ5bGLxx047zXnfrmZj3unJzO1+lJEmS1LoMrlKOKz5gV06e0I/Rn3yc2FB73uvnXXl8+afteo2SJElSazK4Snli/Pg9Gb1pY8Z5r89u7crvn/uUtZ9Vtes1SpIkSa3B4CrlkfHj98w87xVYU9iV379czrL1le18lZIkSVLLMrhKeabkK/04a+tHDHhvY2JD7aHDb1fy+NqK9r1ISZIkqQUZXKU8VHx4f76961ZGP//mjkOHgWfXVfH7V8sdOixJkqQOweAq5asx+zB+7B4c+8rqzEOHP438/tUKhw5LkiQp7xlcpXw2qDclZxzAWevezTx0OMKCdxw6LEmSpPxmcJU6gOLj9uPb2z5i9LIMQ4cjPPuBQ4clSZKUvwyuUkcx6SDG967i2GdW7Dh0OKaGDlc6dFiSJEl5x+AqdSSTDqLkkN0568/P1TF0OLLgnSqHDkuSJCmvGFyljmbMPhRP2IdvP7i4jqHD0aHDkiRJyisGV6kjGrMPnDGM8Uter3vo8GcOHZYkSVJ+MLhKHdWYfeDfDqek4nPOeiDD0GECkcTQ4XtWVVh9lSRJUs4yuEod2aDe8G+HUzyiT+ahwySGDr+2yeqrJEmScpfBVeoMJh1U/9BhqK6+2rhJkiRJuaaovS9AUhsZsw8AJf/9Iv02fsrfhg/ktX37Jd5LDh1ONG6CtZ+VM764kOIe/m5LkiRJ7c+/lUqdSbJpU/GHmzj5sec59pmVGRo3RdZ8hkOHJUmSlDOsuEqdzZh94Es94S9vUPLCWvpt/JTHDx3Mmv69aw0dhgXvVPHSR1VWXyVJktSu/Juo1BkN6g3TSqurr5kbNyWs+Qx+92qlc18lSZLUbgyuUmeWXDKHvXZh/OIMjZvSPPtB5PevlrtsjiRJktqcwVXq7Ab1hm8Ph8JAyStrd1zzNS3AOvdVkiRJ7cHgKikRXi8tg/17U/xBYujwsU+voNfmzxPvp4XX1NxXhw5LkiSprYRYazhgListLY2LFy9u78uQOrZ7V8Kjq6pfPl76Tzw7Yj8IVDduSunVBQ7fq4CSvoVtfJGSJEnqiEIIS2KMpbW3W3GVVNOkg+CMYYmgCvXOff2kPFF9de6rJEmSWpPBVdKOUk2b9u8NkHnuaxrnvkqSJKk1GVwlZTaodyK8HjMIoHrua41lc5z7KkmSpDZgcJVUvwxDh8964O91Vl+f/SBy40vlVl8lSZLUYgyukhpWa+hweufh7ZVX575KkiSpdRhcJWWn1tBhqDX3NTV8OM2az+B3r1YaYCVJktQsBldJjVNr6HDGua+1pAKs818lSZLUFAZXSY03Zh84fViNTTXmvtYaOpzy7AfR6qskSZIaLcQM1ZFcVVpaGhcvXtzelyEp5Zm34a4Xd8ioa/fYlccPHcya/r0hhIyHDt418JU9Cyju4e/PJEmSlBBCWBJjLK293b8xSmq6Wk2bUtKbN/X6YiuZqq+vbYqu/SpJkqSsWHGV1DLuXQmPrsr41uOH/hPPjtivzurrgB4wvrjQ6qskSVIn16yKawjh2BDCKyGE10MIV2R4f1wIYVMIYVny5yfJ7XuHEB4PIawMISwPIVycdszMEMLatGOOa84XlNTOajVtSjf+ude3L52Tgc2bJEmSVJ+ihnYIIRQCvwaOAdYAz4UQ7o8xrqi169MxxuNrbasA/i3GuDSE0BNYEkJ4NO3YX8QYr2vmd5CUK8bsA1/qCX95A15YV+OtklfW0m/jp/ztkEG8Vtw3Y/X12Q8iKzeWc/heBZT0LWyrq5YkSVKOy6biehjweoxxVYxxGzAPODGbk8cY34sxLk0+3wysBIqberGS8sCg3jCtNGP1tfiDTZz88D846/6/M+CjT8g09/WTcljwTpXdhyVJklQtm+BaDLyT9noNmcNnWQjh+RDCwyGEg2u/GUIYCIwEnk3bfGEI4YUQwq0hhN61j5GUx+po3ATJ5k33/C3RvKmiPOPhqeHD96yqMMBKkiR1ctkE10zdVGqXSZYC+8YYRwD/D5hf4wQh7ALcA1wSY/wkufkmYH+gBHgP+I+MHx7C1BDC4hDC4g8//DCLy5WUMwb1ToTXYwZlfLvk5bVccNvjjP74ozpP8dqmaICVJEnq5LIJrmuAvdNeDwDeTd8hxvhJjPHT5POHgC4hhL4AIYQuJELrnTHGP6Udsy7GWBljrAJuITEkeQcxxptjjKUxxtJ+/fo14qtJyhmTDoLvZ66+Aoz/w2LOWrKCAQV1N2dy+RxJkqTOK5vg+hwwOISwXwihK3AacH/6DiGEvUJIdFoJIRyWPO+G5LbfACtjjP9Z65j+aS8nAS81/WtIynmp6msdnYeLl67h2zf/L8du/bjOU0QS819vWVFugJUkSepEGuwqHGOsCCFcCDwCFAK3xhiXhxCmJd+fA5wCnB9CqAC+AE6LMcYQwhjgLODFEMKy5Cl/mKzKzg4hlJD4u+hq4Lst+s0k5aZU5+F7V8IbG2u+F6Hkt3+n3/FD+NuBA3jtk8yn2LA1EWD/+n6VHYglSZI6gRDrWFcxF5WWlsbFixe392VIain3roRHV2V+7596s/b4g/lb4c51BtiUAT1gfHEhxT2yWppakiRJOSqEsCTGWLrDdoOrpHb1zNtw14uZVsZJGLEna8cPzirADt418JU9CwywkiRJecrgKil3rdqYeehwSgBOH8bakQN4fE0laz6v/3QGWEmSpPxkcJWU++obOgyJZXUmHcTaz6oMsJIkSR1QXcHVv81Jyh2TDqqz6zCQCLX/+VeK123i2wd24di96/9PmGvASpIkdQxWXCXlnlUb4S9vwAvrMr8fgKO3V1//9n5lg/NfwQqsJElSrnOosKT809Dc13/qDRMPgkG9DbCSJEkdgMFVUv5qaO7riD3hmP0NsJIkSXnO4Copv2XZeZgx+wAYYCVJkvKQwVVSx5Bl5+EUA6wkSVL+MLhK6jieeRvuehHq+s/X7t3h2MHV1VdoXIAd0APGFxcaYCVJktqYwVVSx9JQ52Go0bwpxQArSZKUuwyukjqmRs59TTHASpIk5R6Dq6SOraG5rxmqr5AIsC9uqGLtZ5EPt9T/EQZYSZKk1mVwldTxNVR9hR2aN6Vbtr6Sv75fxSfl9X9Mv+5QvEtg2O42cpIkSWpJBldJnUdDzZvqqL6mZBtgwU7EkiRJLcngKqlzyab6OmJPOGZ/A6wkSVKOMLhK6pyeeRsWvAYf1TGBtY7mTekaE2D7dIND9yigpG9h065XkiSpEzO4Surcmti8Kd2y9ZU890EVG7Y2/HG9usDhexlgJUmSGsPgKkkNzX2FBocPQ+OW0tmtK+xUBCP6GGIlSZIaYnCVJEjMff3LG/DCuvr3a+EAC1ZhJUmSGmJwlaR02TRvymL+KzRuLViAnQsTy+nYzEmSJKkmg6skZfLM2/C/q+D9z+reJ4v5rylrP6vi8TWVrPk8u493TVhJkqTtDK6SVJ9s5r8eMwgmHZTV6RpbhQWX1JEkSaoruBa1x8VIUs4Zsw98qWf9818fXQVL3oVjBzc4fLi4x/YAmm0V9rVNkdc2VdKnW6VL6kiSJKWx4ipJtWUz/7URw4dTUs2c1n4Gn1c2vL9zYSVJUmfjUGFJaqxn3oYFr8FH9Yz1zaL7cCaNWRMWnAsrSZI6B4OrJDXVvSsTw4TrkmX34Uwau6QOQJ9uOJRYkiR1SAZXSWqOVho+nNKUZk67dYWdimBEH0OsJEnqGAyuktQSsuk+3IwAC42fCwvOh5UkSR2DwVWSWsqqjfV3H05pxPI5dWnsXFiwEitJkvKXwVWSWlo2w4eLeyYqr6MHNLkCC00bSgxWYiVJUn4xuEpSa8mm+zA0uQNxbU0NsVZiJUlSrjO4SlJra+MAC02bDwtWYiVJUm4yuEpSW2lo+ZyUFgywkJgP+/yGKr6ogI+3ZX+clVhJkpQrDK6S1JaybeDUjDVg69PUSuxuXaEwwO7drcZKkqS2Z3CVpPaQbYBt5hI69WlqJRagX/fEkOJhuxtiJUlS6zO4SlJ7yoEAC02vxAL06gJ77mwlVpIktR6DqyTlghwJsNC8SqzzYiVJUmswuEpSLslmDVhokwAL25fYWb8l8tGWxnco7tEFigoMspIkqXkMrpKUi7JdQqeNAmzKsvWVPPdBFRu2Nv7YnQth9+7QdyfnxkqSpMYxuEpSLsvRANucSmyKc2MlSVK2DK6SlA9yNMCmNGdeLCRCbLdChxVLkqTMDK6SlE+yDbB77QJf3a/F14HNRqpD8UdboTI2Lcg6P1aSJKUzuEpSPso2wO7eHY4d3C4BNiUVZNd9AZ+UN+0cBllJkjq3ZgXXEMKxwC+BQmBujPHaWu+PA+4D3kxu+lOM8ar6jg0h7A78DzAQWA18M8ZYb3tNg6ukTiuPAizUnBv7yTaDrCRJyk6Tg2sIoRB4FTgGWAM8B5weY1yRts844PsxxuOzPTaEMBv4KMZ4bQjhCqB3jHFGfddicJXU6T3zNvzvKnj/s/r3y5EAm9ISw4rBICtJUkdXV3AtyuLYw4DXY4yrkieaB5wIrKj3qIaPPREYl9zvDuAJoN7gKkmd3ph9Ej8NrQP70Rb47xcTVdocCLDFPQo4ef/tHYWbGmQ/r9ze2fi9z6v427oqCgMUBMOsJEkdWTbBtRh4J+31GmB0hv3KQgjPA++SqL4ub+DYPWOM7wHEGN8LIezR2IuXpE5rUG/4t8OzD7APvJI45pj927wTcSYtFWRr7/fe51U89W4VPbpAVYTdu7sMjyRJHUE2wTVk2FZ7fPFSYN8Y46chhOOA+cDgLI+t/8NDmApMBdhnn9wY8iZJOSPbALt5Gzy/LvHTTkvp1KelgizUrMpu2Bp5bVMlu3WtpDAYZCVJylfZBNc1wN5prweQqKpWizF+kvb8oRDCjSGEvg0cuy6E0D9Zbe0PfJDpw2OMNwM3Q2KOaxbXK0mdT7YBFuD1jXDdX3MywKa0ZJCF7fvXDrIOMZYkKT9k05ypiESDpQnAWhINls5IDgVO7bMXsC7GGEMIhwF/BPYl0Uk447EhhJ8DG9KaM+0eY5xe37XYnEmSspRNgE3J4QBbl/SuxV9UNK/hU0qq8ZNDjCVJaj/NXQ7nOOB6EkH01hjjT0MI0wBijHNCCBcC5wMVwBfAZTHGv9Z1bHJ7H+BuYB/gbeDUGONH9V2HwVWSGmnVRvjLG/DmxsRw4foU90yE19ED8irEpqRXZQsCfFa+fchwU/XqAt0KE2F2pyLou1Ng2O4GWkmSWkuzgmuuMLhKUjNkuxYs5GUVNpNl6yt5fkMVFVUtE2RT0gOt1VlJklqOwVWSlNAJA2xKepCtii0zxDhlt644b1aSpGYyuEqSampMgM3zYcT1qT3EeGslfFLeMudOnze7U1Hip0cXhxtLklQXg6skKbNn3ob/7+3EWNr1nze8/4g9c2Y92NbSmmE2xfmzkiTtyOAqSWpYY6qwe+0CX90PxnSONbZrdzJuqQZQtaUHWocdS5I6G4OrJCl7jQmwu3eHYwd3mgBbW2vOm02XPuy4INgYSpLUMRlcJUmN98zb8L+r4P3PGt63Z9fE8OEOPow4G7WHGqfC5odZ/B6gKfp1T1RpU5Vghx9LkvKVwVWS1HSp9WBfWJfd/h24mVNzZBpu3BrzZ2urPfzYaq0kKVcZXCVJzbdqI/xtDby5EdZuzu6YTtDMqbkyBdrWHHacbteuUBRqVoYNtpKk9mJwlSS1rFUb4d6V8MbG7Pb/p97Qv6dV2Eaqa9hxazSGyqRnEXQvhCoMt5Kk1mdwlSS1jtQw4jc3wuYsy4OdrCNxa0k1hioMiddtOfw43a5dEt2PawdbuyJLkhrL4CpJan2NaeYENnRqRXUNP27Lam26nQuhR1GicrtTUWKbzaQkSbUZXCVJbaexzZzAhk5trPYyPunBtq0rtrX17JIcnhyt4kpSZ2NwlSS1vVQzp/c3w+tZzoUFhxLngLrm1rZn1ba2nQth5yKIZK7iWs2VpPxjcJUkta+mdCR2KHFOq69q21ZdkRurZ1FiaaBI5kBu8ylJal8GV0lS7mhKQyeHEuelTJXb2tXR9h6a3JDdu0L3osR1NhR2rfJKUvMYXCVJuamxDZ3AocQdUH3NpHK9ituQXdKWFCqsI7xb+ZWkBIOrJCm3NWUocd+dYZcucPg+hthOJJsqbq40mmpJPYsSjakKQ80QnKnaC/WHYivCknKVwVWSlD+aMpTY+bCqQ7bV3FxrPtVWehRun/dbGBJV7cJQcx5wYyrEVo4lNYfBVZKUn5oylNj5sGoBqeZThSHxOtvQ1pGqvK2hZ1HizylVOd6pCAKJP9/agbmpj80N2i65JLUfg6skKb81ZSgxwO47wd69rMSqTTVU5c02WHWmym8u6l4IO6WtKRyT2yDxC4oQIMaalerUY/oxrR202/rcXm/+Xm8+jHwwuEqSOo6mhlgrscpDDS071Ni/9FoRljq3ggBnDi7M2fBaV3Atao+LkSSpWQb13h48GzMfdu3mxM/Tb1uJVd4o6VvY4kNWGzvvt7kVICvHUu6oivD25khxj/a+ksYxuEqS8tug3jAt+YvZxsyH/eiLxM/z66zEqtMp7tH2QwXrqhzn2lDLfFxySWqMggD79AztfRmN5lBhSVLHkxpK/P5mWPdZ9p2JwUqspIxLLuVq0O5oczC9Xue4OlRYktR5pA8lhqZXYg2xUqdU3KOAk/fP3b/YS52RwVWS1PGN2Sfx09hKbHqI7bsz7NIFDk+eS5IktRmDqySp82hOJXb957AeWP0iPPAK7NkD+vd0XqwkSW3A4CpJ6rwyVWI/+gI+2lL/cZu3JX5e32iHYkmS2oDBVZKk2pXYxiyxAw4pliSpldlVWJKk+jzzNvx/bycWolz/eeOO7dnVIcWSJDWCXYUlSWqKMWmV01Qlds2mhocTw45Diot7QpcCq7GSJDWSwVWSpGwN6g3Tkr8EbspasWs3Jx5TDZ56dTPISpKUBYOrJElNkalDcWOGFKeqsWCnYkmSGmBwlSSpJTRnSDHYqViSpHoYXCVJammZhhRv3pqoxKaGCzekdqfiogB77mKQlSR1SgZXSZJaU11L7XzwKVTE7IYVp/Z5/zODrCSpUzK4SpLUltKrsdC0YcW1g2xxz0SY7dXN+bGSpA7J4CpJUntqbqdiSAw/Tg1BTs2P3anIjsWSpA7D4CpJUq6oq1NxRRV8sjX7IPvRF9uf27FYktQBGFwlScpVY2pVS5saZDN1LLYiK0nKIwZXSZLyRX1BNttuxZC5Iturm0FWkpSzDK6SJOWr2mvHpubHfrot+47FsL0iCzWHFkMiFBtmJUntzOAqSVJHUHt+LDStYzHUDLJgVVaS1O4MrpIkdVR1dSxubEUWMldle3WDyirXk5UktbqsgmsI4Vjgl0AhMDfGeG0d+x0K/A34VozxjyGEA4H/SdtlEPCTGOP1IYSZwHnAh8n3fhhjfKhpX0OSJNWrvorsB582L8im1pPtuzMUBYOsJKnFNRhcQwiFwK+BY4A1wHMhhPtjjCsy7DcLeCS1Lcb4ClCS9v5a4N60w34RY7yumd9BkiQ1RXpFFmoG2V26whcVjWv6lAq+tYPsLl1dikeS1CzZVFwPA16PMa4CCCHMA04EVtTa73vAPcChdZxnAvBGjPGtJl6rJElqTbWDLDSvKlu972c1l+LZvXtis42fJElZyia4FgPvpL1eA4xO3yGEUAxMAr5K3cH1NOCuWtsuDCFMBhYD/xZj3Fj7oBDCVGAqwD77+D82SZLaVH1V2cKCxq0nC4mleOpajsf5spKkOmQTXEOGbbHW6+uBGTHGyhB23D2E0BU4AfhB2uabgKuT57oa+A/gnB0+KMabgZsBSktLa3+uJElqS5mqsunryTY2yEL982ULC+xkLEnKKriuAfZOez0AeLfWPqXAvGRo7QscF0KoiDHOT77/dWBpjHFd6oD05yGEW4A/N/rqJUlS+xtTK1SmB9kvyhu3FE9K7SHJVmYlqVPLJrg+BwwOIexHornSacAZ6TvEGPdLPQ8h3A78OS20ApxOrWHCIYT+Mcb3ki8nAS819uIlSVIOqh1kay/F05TGT1B/ZXaXrtCjayLY2gRKkjqcBoNrjLEihHAhiW7BhcCtMcblIYRpyffn1Hd8CGFnEh2Jv1vrrdkhhBISQ4VXZ3hfkiR1BJmW4oHmz5eFmg2gUlJNoHYqSlRn7WosSXkvxJg/00ZLS0vj4sWL2/syJElSa0kfZlxZ1fhOxg1JD7QON5aknBNCWBJjLK29PZuhwpIkSW2j9jBjaJnKbEp6R+NMjaAMtJKUkwyukiQptzXUybiyKhE6GztnNqV2RTfT/Flw3VlJakcGV0mSlH/qqsymN4EqLGh6V2PIPH+2dndjl+uRpDZhcJUkSR1DfU2gagfa5gw3Tu9unJIp0DrsWJJajMFVkiR1bHUF2kzDjVs60NY1j9ZOx5LUKAZXSZLUOWUabgw7BtqmrjubbofOyJ/B6xsTS/fYHEqSGmRwlSRJSldXoK3d3billuupsznUTlBUsP2zDLaSOjGDqyRJUjYydTeGzIG2ucOOAdZ/kXm7w48ldUIGV0mSpOaoK9BC5nm0rVWpTR9+XNyz5udZrZWU5wyukiRJraWuYcfQ8s2h0tU1H7euaq3BVlKOM7hKkiS1h2ybQ7Xk8OOUuqq99Q1DhsQ1uWatpHZgcJUkScol9VVpIXOw/aIcPtrScteQaRhySl1r1lq1ldSKDK6SJEn5pL6ux39bA5u3wmfb4NNtrVOthcxr1qY01BW5sAC6FFi5ldQoBldJkqSOYFDvhqucbTEMOaWursgpqcrtnj0Sr2sHbau3ktIYXCVJkjqLpgxDTs1x/aKi7qZPTVVf5RYabiZl9VbqNAyukiRJSmgo2Na1Zm1rVW1TGlo6aPWLcP/L0Ks7VKU1k6pdxTXkSnkrxBjb+xqyVlpaGhcvXtzelyFJkqS61DccuaXWsG2uXbrCrnU0l0qvMvfvCaMHOFRZakMhhCUxxh0Wx7biKkmSpJbTUNUWalZu66qOtlb1NvVZnzZ07s/g9Y3w9Nuwe3fYqUvNpYGs5kptyoqrJEmSclM+VG9ry6aaa9CV6mTFVZIkSfmlsdXb9GG+ULMq2lYhN6tqblJqbm6/HlAQEssY1Rd27bSsTszgKkmSpPw1qDdM26E4k1lDzaVSj1+Uw0dbWve6Uz4th08/zn7/VKfl3bsnqrZFhQ3P1YVE1doKr/KYwVWSJEmdQ2ND7t/WwPuba1Zu27Oamy7rYP3Z9qepCm/PbhBjw9VdhzYrhxhcJUmSpNoG9W7ccNxsq7ntPTf30/LET1M0ZWizXZrVQgyukiRJUnM1ppoL2XVWbqt1chujsUObq6V1ae6d7NJcVc/Q5rr+LKz8dlp2FZYkSZLyRUOdljMFwS8qYO3m9r7yltWjC/TsClURumQ5zzdTGLbZVc6xq7AkSZKU77LptJxJY4Yy59LQ5rp8Vp74yW7nut9KNbvq3Q0KCxMV3cbM/80Uih0W3SoMrpIkSVJH19ihzLU1ZWhze3RpbqqNW5t4YKZQnDYsetdusFNRIgw31AE62+HSnTQcG1wlSZIk1a8lgm+mLs2NCW25WPltyKatiZ9GqadCnL5PKhzv1i0xZ7iiKjFsOtPc4Q4wNNrgKkmSJKl1NbZLc12aMuS5rjCcC82uWsLHWxM/2Xj/M3jpA7i0LO/Cq8FVkiRJUn5obuW3tsY2u2ooFOfDsOjKCK9uMLhKkiRJUl5oarOr+mQ7LLqpc1ybG44LAxzQp2W+axsyuEqSJElSS2mpYdH1aWo4do6rJEmSJKlNtEU4zjEF7X0BkiRJkiTVx+AqSZIkScppBldJkiRJUk4zuEqSJEmScprBVZIkSZKU0wyukiRJkqScZnCVJEmSJOU0g6skSZIkKacZXCVJkiRJOc3gKkmSJEnKaVkF1xDCsSGEV0IIr4cQrqhnv0NDCJUhhFPStq0OIbwYQlgWQlictn33EMKjIYTXko+9m/dVJEmSJEkdUYPBNYRQCPwa+DowBDg9hDCkjv1mAY9kOM34GGNJjLE0bdsVwMIY42BgYfK1JEmSJEk1ZFNxPQx4Pca4Ksa4DZgHnJhhv+8B9wAfZPnZJwJ3JJ/fAUzM8jhJkiRJUieSTXAtBt5Je70mua1aCKEYmATMyXB8BP4SQlgSQpiatn3PGON7AMnHPRpz4ZIkSZKkzqEoi31Chm2x1uvrgRkxxsoQdtj9iBjjuyGEPYBHQwgvxxifyvYCk2F3KsA+++yT7WGSJEmSpA4im4rrGmDvtNcDgHdr7VMKzAshrAZOAW4MIUwEiDG+m3z8ALiXxNBjgHUhhP4AyceMQ4xjjDfHGEtjjKX9+vXL5jtJkiRJkjqQEGPt4mmtHUIoAl4FJgBrgeeAM2KMy+vY/3bgzzHGP4YQegAFMcbNyeePAlfFGBeEEH4ObIgxXpvsVLx7jHF6A9fyIfBW475im+sLrG/vi1BO8t5QXbw3VB/vD9XFe0N18d5QfXL9/tg3xrhDxbLBocIxxooQwoUkugUXArfGGJeHEKYl3880rzVlT+De5PDhIuC/Y4wLku9dC9wdQvhX4G3g1CyuJedLriGExbW6J0uA94bq5r2h+nh/qC7eG6qL94bqk6/3RzZzXIkxPgQ8VGtbxsAaY5yS9nwVMKKO/TaQqOJKkiRJklSnbOa4SpIkSZLUbgyuLe/m9r4A5SzvDdXFe0P18f5QXbw3VBfvDdUnL++PBpszSZIkSZLUnqy4SpIkSZJymsG1hYQQjg0hvBJCeD25vI86kRDC3iGEx0MIK0MIy0MIFye37x5CeDSE8FrysXfaMT9I3i+vhBC+1n5Xr7YQQigMIfwjhPDn5GvvDQEQQtgthPDHEMLLyf+GlHl/CCCEcGny/ykvhRDuCiF0997ovEIIt4YQPgghvJS2rdH3QwjhkBDCi8n3bgjJ5T+Uv+q4N36e/P/KCyGEe0MIu6W9l5f3hsG1BYQQCoFfA18HhgCnhxCGtO9VqY1VAP8WYzwI+Arwf5L3wBXAwhjjYGBh8jXJ904DDgaOBW5M3kfquC4GVqa99t5Qyi+BBTHGL5PoxL8S749OL4RQDFwElMYYh5JYkvA0vDc6s9tJ/LNN15T74SZgKjA4+VP7nMo/t7PjP8dHgaExxuHAq8APIL/vDYNryzgMeD3GuCrGuA2YB5zYztekNhRjfC/GuDT5fDOJv3gWk7gP7kjudgcwMfn8RGBejHFrjPFN4HUS95E6oBDCAOAbwNy0zd4bIoTQCzgK+A1AjHFbjPFjvD+UUATsFEIoAnYG3sV7o9OKMT4FfFRrc6PuhxBCf6BXjHFRTDS6+W3aMcpTme6NGONfYowVyZd/AwYkn+ftvWFwbRnFwDtpr9ckt6kTCiEMBEYCzwJ7xhjfg0S4BfZI7uY907lcD0wHqtK2eW8IYBDwIXBbcij53BBCD7w/Or0Y41rgOuBt4D1gU4zxL3hvqKbG3g/Fyee1t6tjOwd4OPk8b+8Ng2vLyDT+23bNnVAIYRfgHuCSGOMn9e2aYZv3TAcUQjge+CDGuCTbQzJs897ouIqAUcBNMcaRwGckh/rVwfujk0jOVTwR2A/4EtAjhPDt+g7JsM17o/Oq637wPulkQgj/l8SUtjtTmzLslhf3hsG1ZawB9k57PYDEcB51IiGELiRC650xxj8lN69LDr0g+fhBcrv3TOdxBHBCCGE1iWkEXw0h/B7vDSWsAdbEGJ9Nvv4jiSDr/aGjgTdjjB/GGMuBPwGH472hmhp7P6xh+5DR9O3qgEIIZwPHA2fG7Wug5u29YXBtGc8Bg0MI+4UQupKY8Hx/O1+T2lCy69pvgJUxxv9Me+t+4Ozk87OB+9K2nxZC6BZC2I/EBPi/t9X1qu3EGH8QYxwQYxxI4r8N/xtj/DbeGwJijO8D74QQDkxumgCswPtDiSHCXwkh7Jz8f8wEEv0TvDeUrlH3Q3I48eYQwleS99XktGPUgYQQjgVmACfEGD9Peytv742i9r6AjiDGWBFCuBB4hETXv1tjjMvb+bLUto4AzgJeDCEsS277IXAtcHcI4V9J/CXkVIAY4/IQwt0k/oJaAfyfGGNlm1+12pP3hlK+B9yZ/MXnKuA7JH6x7P3RicUYnw0h/BFYSuKf9T+Am4Fd8N7olEIIdwHjgL4hhDXAlTTt/yXnk+hCuxOJeY8Po7xWx73xA6Ab8GhyVZu/xRin5fO9EbZXjSVJkiRJyj0OFZYkSZIk5TSDqyRJkiQppxlcJUmSJEk5zeAqSZIkScppBldJkiRJUk4zuEqSJEmScprBVZIkSZKU0wyukiRJkqSc9v8DjINAdegwV8oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.7436 - accuracy: 0.6493 - val_loss: 0.7747 - val_accuracy: 0.6406\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7339 - accuracy: 0.6545 - val_loss: 0.7624 - val_accuracy: 0.6406\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7251 - accuracy: 0.6545 - val_loss: 0.7511 - val_accuracy: 0.6406\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.6562 - val_loss: 0.7409 - val_accuracy: 0.6406\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.6562 - val_loss: 0.7320 - val_accuracy: 0.6406\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.6562 - val_loss: 0.7239 - val_accuracy: 0.6406\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.6562 - val_loss: 0.7165 - val_accuracy: 0.6406\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6930 - accuracy: 0.6562 - val_loss: 0.7095 - val_accuracy: 0.6406\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6881 - accuracy: 0.6562 - val_loss: 0.7030 - val_accuracy: 0.6406\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6835 - accuracy: 0.6562 - val_loss: 0.6970 - val_accuracy: 0.6406\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6793 - accuracy: 0.6562 - val_loss: 0.6916 - val_accuracy: 0.6406\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.6562 - val_loss: 0.6868 - val_accuracy: 0.6406\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.6562 - val_loss: 0.6825 - val_accuracy: 0.6406\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6562 - val_loss: 0.6787 - val_accuracy: 0.6406\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6659 - accuracy: 0.6562 - val_loss: 0.6751 - val_accuracy: 0.6406\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6562 - val_loss: 0.6717 - val_accuracy: 0.6406\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6606 - accuracy: 0.6562 - val_loss: 0.6686 - val_accuracy: 0.6406\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6581 - accuracy: 0.6562 - val_loss: 0.6658 - val_accuracy: 0.6406\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6562 - val_loss: 0.6630 - val_accuracy: 0.6406\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6562 - val_loss: 0.6603 - val_accuracy: 0.6406\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6562 - val_loss: 0.6577 - val_accuracy: 0.6406\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6562 - val_loss: 0.6552 - val_accuracy: 0.6406\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6562 - val_loss: 0.6528 - val_accuracy: 0.6406\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6562 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6562 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6562 - val_loss: 0.6461 - val_accuracy: 0.6406\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6393 - accuracy: 0.6562 - val_loss: 0.6440 - val_accuracy: 0.6406\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6562 - val_loss: 0.6422 - val_accuracy: 0.6406\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6562 - val_loss: 0.6404 - val_accuracy: 0.6406\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6562 - val_loss: 0.6386 - val_accuracy: 0.6406\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6528 - val_loss: 0.6369 - val_accuracy: 0.6406\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6528 - val_loss: 0.6353 - val_accuracy: 0.6406\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6528 - val_loss: 0.6337 - val_accuracy: 0.6406\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.6528 - val_loss: 0.6321 - val_accuracy: 0.6406\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6528 - val_loss: 0.6305 - val_accuracy: 0.6406\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6528 - val_loss: 0.6290 - val_accuracy: 0.6406\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6528 - val_loss: 0.6274 - val_accuracy: 0.6406\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6528 - val_loss: 0.6259 - val_accuracy: 0.6406\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6528 - val_loss: 0.6245 - val_accuracy: 0.6406\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6545 - val_loss: 0.6230 - val_accuracy: 0.6406\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6545 - val_loss: 0.6217 - val_accuracy: 0.6406\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6167 - accuracy: 0.6562 - val_loss: 0.6203 - val_accuracy: 0.6406\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.6580 - val_loss: 0.6190 - val_accuracy: 0.6406\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6597 - val_loss: 0.6177 - val_accuracy: 0.6406\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.6597 - val_loss: 0.6164 - val_accuracy: 0.6406\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6114 - accuracy: 0.6597 - val_loss: 0.6152 - val_accuracy: 0.6406\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6615 - val_loss: 0.6140 - val_accuracy: 0.6406\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6615 - val_loss: 0.6128 - val_accuracy: 0.6406\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6615 - val_loss: 0.6117 - val_accuracy: 0.6406\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6597 - val_loss: 0.6106 - val_accuracy: 0.6406\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6615 - val_loss: 0.6094 - val_accuracy: 0.6406\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6038 - accuracy: 0.6632 - val_loss: 0.6083 - val_accuracy: 0.6406\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6615 - val_loss: 0.6072 - val_accuracy: 0.6562\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6632 - val_loss: 0.6062 - val_accuracy: 0.6562\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6632 - val_loss: 0.6051 - val_accuracy: 0.6615\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6684 - val_loss: 0.6041 - val_accuracy: 0.6667\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6667 - val_loss: 0.6030 - val_accuracy: 0.6719\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5966 - accuracy: 0.6667 - val_loss: 0.6020 - val_accuracy: 0.6823\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5955 - accuracy: 0.6667 - val_loss: 0.6009 - val_accuracy: 0.6823\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.6684 - val_loss: 0.5998 - val_accuracy: 0.6875\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6684 - val_loss: 0.5987 - val_accuracy: 0.6875\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5920 - accuracy: 0.6719 - val_loss: 0.5977 - val_accuracy: 0.6875\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6719 - val_loss: 0.5967 - val_accuracy: 0.6875\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.6719 - val_loss: 0.5956 - val_accuracy: 0.6875\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6736 - val_loss: 0.5946 - val_accuracy: 0.6979\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6736 - val_loss: 0.5936 - val_accuracy: 0.6979\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6736 - val_loss: 0.5927 - val_accuracy: 0.6979\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6736 - val_loss: 0.5917 - val_accuracy: 0.6979\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5841 - accuracy: 0.6736 - val_loss: 0.5908 - val_accuracy: 0.6979\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.6736 - val_loss: 0.5899 - val_accuracy: 0.7031\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.6771 - val_loss: 0.5890 - val_accuracy: 0.7083\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.6771 - val_loss: 0.5882 - val_accuracy: 0.7083\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6771 - val_loss: 0.5873 - val_accuracy: 0.7083\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.6806 - val_loss: 0.5864 - val_accuracy: 0.7083\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.6823 - val_loss: 0.5856 - val_accuracy: 0.7083\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6823 - val_loss: 0.5847 - val_accuracy: 0.7083\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5757 - accuracy: 0.6823 - val_loss: 0.5839 - val_accuracy: 0.7135\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.6823 - val_loss: 0.5830 - val_accuracy: 0.7135\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6840 - val_loss: 0.5822 - val_accuracy: 0.7188\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5726 - accuracy: 0.6840 - val_loss: 0.5813 - val_accuracy: 0.7188\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.6858 - val_loss: 0.5805 - val_accuracy: 0.7188\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6875 - val_loss: 0.5796 - val_accuracy: 0.7240\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.6875 - val_loss: 0.5788 - val_accuracy: 0.7240\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.6892 - val_loss: 0.5780 - val_accuracy: 0.7240\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.6927 - val_loss: 0.5771 - val_accuracy: 0.7292\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7014 - val_loss: 0.5763 - val_accuracy: 0.7344\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7031 - val_loss: 0.5755 - val_accuracy: 0.7344\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7031 - val_loss: 0.5747 - val_accuracy: 0.7396\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7083 - val_loss: 0.5739 - val_accuracy: 0.7396\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5629 - accuracy: 0.7083 - val_loss: 0.5731 - val_accuracy: 0.7344\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7066 - val_loss: 0.5723 - val_accuracy: 0.7344\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7066 - val_loss: 0.5716 - val_accuracy: 0.7344\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7066 - val_loss: 0.5708 - val_accuracy: 0.7344\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7083 - val_loss: 0.5700 - val_accuracy: 0.7344\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5583 - accuracy: 0.7083 - val_loss: 0.5693 - val_accuracy: 0.7344\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7101 - val_loss: 0.5685 - val_accuracy: 0.7344\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7118 - val_loss: 0.5678 - val_accuracy: 0.7344\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7153 - val_loss: 0.5670 - val_accuracy: 0.7344\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7170 - val_loss: 0.5663 - val_accuracy: 0.7344\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7170 - val_loss: 0.5655 - val_accuracy: 0.7240\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7188 - val_loss: 0.5647 - val_accuracy: 0.7292\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7205 - val_loss: 0.5640 - val_accuracy: 0.7292\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7222 - val_loss: 0.5633 - val_accuracy: 0.7292\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7188 - val_loss: 0.5625 - val_accuracy: 0.7292\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7222 - val_loss: 0.5618 - val_accuracy: 0.7292\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7222 - val_loss: 0.5611 - val_accuracy: 0.7292\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7222 - val_loss: 0.5604 - val_accuracy: 0.7292\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7222 - val_loss: 0.5597 - val_accuracy: 0.7292\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7205 - val_loss: 0.5590 - val_accuracy: 0.7292\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7205 - val_loss: 0.5583 - val_accuracy: 0.7292\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7222 - val_loss: 0.5576 - val_accuracy: 0.7292\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7240 - val_loss: 0.5569 - val_accuracy: 0.7292\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7240 - val_loss: 0.5562 - val_accuracy: 0.7292\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7240 - val_loss: 0.5556 - val_accuracy: 0.7292\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7240 - val_loss: 0.5549 - val_accuracy: 0.7344\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7240 - val_loss: 0.5542 - val_accuracy: 0.7396\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7240 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7222 - val_loss: 0.5529 - val_accuracy: 0.7344\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7222 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7240 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7274 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7274 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7274 - val_loss: 0.5498 - val_accuracy: 0.7448\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7292 - val_loss: 0.5492 - val_accuracy: 0.7448\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7309 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7309 - val_loss: 0.5480 - val_accuracy: 0.7500\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7326 - val_loss: 0.5474 - val_accuracy: 0.7500\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7326 - val_loss: 0.5468 - val_accuracy: 0.7500\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7344 - val_loss: 0.5462 - val_accuracy: 0.7500\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7378 - val_loss: 0.5457 - val_accuracy: 0.7500\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7396 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.7396 - val_loss: 0.5447 - val_accuracy: 0.7448\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.7396 - val_loss: 0.5442 - val_accuracy: 0.7448\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7396 - val_loss: 0.5437 - val_accuracy: 0.7396\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7413 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7396 - val_loss: 0.5428 - val_accuracy: 0.7396\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7413 - val_loss: 0.5423 - val_accuracy: 0.7396\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7396 - val_loss: 0.5419 - val_accuracy: 0.7396\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7413 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7413 - val_loss: 0.5410 - val_accuracy: 0.7396\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7413 - val_loss: 0.5406 - val_accuracy: 0.7448\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7413 - val_loss: 0.5401 - val_accuracy: 0.7448\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7431 - val_loss: 0.5397 - val_accuracy: 0.7448\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7431 - val_loss: 0.5393 - val_accuracy: 0.7448\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7431 - val_loss: 0.5389 - val_accuracy: 0.7448\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7431 - val_loss: 0.5386 - val_accuracy: 0.7448\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.7483 - val_loss: 0.5382 - val_accuracy: 0.7448\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.7465 - val_loss: 0.5378 - val_accuracy: 0.7448\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7483 - val_loss: 0.5374 - val_accuracy: 0.7448\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7465 - val_loss: 0.5371 - val_accuracy: 0.7448\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7483 - val_loss: 0.5367 - val_accuracy: 0.7500\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7483 - val_loss: 0.5364 - val_accuracy: 0.7500\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.7465 - val_loss: 0.5360 - val_accuracy: 0.7500\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7465 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7465 - val_loss: 0.5354 - val_accuracy: 0.7500\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7448 - val_loss: 0.5351 - val_accuracy: 0.7500\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7431 - val_loss: 0.5347 - val_accuracy: 0.7448\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7465 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.7431 - val_loss: 0.5341 - val_accuracy: 0.7396\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7448 - val_loss: 0.5338 - val_accuracy: 0.7396\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7448 - val_loss: 0.5334 - val_accuracy: 0.7396\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7448 - val_loss: 0.5331 - val_accuracy: 0.7396\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7413 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7413 - val_loss: 0.5324 - val_accuracy: 0.7448\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7431 - val_loss: 0.5321 - val_accuracy: 0.7448\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7431 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7448 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.7465 - val_loss: 0.5312 - val_accuracy: 0.7448\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7448 - val_loss: 0.5309 - val_accuracy: 0.7448\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7483 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7465 - val_loss: 0.5303 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7465 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7465 - val_loss: 0.5297 - val_accuracy: 0.7344\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7465 - val_loss: 0.5295 - val_accuracy: 0.7344\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7448 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7465 - val_loss: 0.5290 - val_accuracy: 0.7344\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7431 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7431 - val_loss: 0.5285 - val_accuracy: 0.7344\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7413 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7413 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7448 - val_loss: 0.5277 - val_accuracy: 0.7344\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7448 - val_loss: 0.5275 - val_accuracy: 0.7344\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7465 - val_loss: 0.5273 - val_accuracy: 0.7344\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7448 - val_loss: 0.5271 - val_accuracy: 0.7344\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7465 - val_loss: 0.5268 - val_accuracy: 0.7396\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7465 - val_loss: 0.5266 - val_accuracy: 0.7396\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7500 - val_loss: 0.5264 - val_accuracy: 0.7396\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7483 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7500 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7500 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7517 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7552 - val_loss: 0.5254 - val_accuracy: 0.7396\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7535 - val_loss: 0.5252 - val_accuracy: 0.7396\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7569 - val_loss: 0.5250 - val_accuracy: 0.7396\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7587 - val_loss: 0.5248 - val_accuracy: 0.7344\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7569 - val_loss: 0.5246 - val_accuracy: 0.7344\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7552 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7587 - val_loss: 0.5242 - val_accuracy: 0.7344\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7587 - val_loss: 0.5240 - val_accuracy: 0.7344\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7587 - val_loss: 0.5238 - val_accuracy: 0.7344\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7587 - val_loss: 0.5236 - val_accuracy: 0.7344\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7587 - val_loss: 0.5234 - val_accuracy: 0.7344\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7639 - val_loss: 0.5232 - val_accuracy: 0.7292\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4853 - accuracy: 0.7639 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7656 - val_loss: 0.5228 - val_accuracy: 0.7292\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.5226 - val_accuracy: 0.7292\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7656 - val_loss: 0.5225 - val_accuracy: 0.7292\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7674 - val_loss: 0.5223 - val_accuracy: 0.7292\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7674 - val_loss: 0.5221 - val_accuracy: 0.7292\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.7674 - val_loss: 0.5219 - val_accuracy: 0.7292\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7674 - val_loss: 0.5218 - val_accuracy: 0.7292\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7674 - val_loss: 0.5216 - val_accuracy: 0.7292\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7674 - val_loss: 0.5215 - val_accuracy: 0.7292\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7674 - val_loss: 0.5213 - val_accuracy: 0.7292\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7674 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7708 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7726 - val_loss: 0.5203 - val_accuracy: 0.7240\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7674 - val_loss: 0.5202 - val_accuracy: 0.7240\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7674 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.7674 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7691 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7691 - val_loss: 0.5195 - val_accuracy: 0.7292\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7691 - val_loss: 0.5194 - val_accuracy: 0.7292\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7691 - val_loss: 0.5192 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7691 - val_loss: 0.5191 - val_accuracy: 0.7292\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.5190 - val_accuracy: 0.7292\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7674 - val_loss: 0.5188 - val_accuracy: 0.7292\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7292\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7292\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7691 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7726 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.5175 - val_accuracy: 0.7396\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.5174 - val_accuracy: 0.7396\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7778 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.5169 - val_accuracy: 0.7396\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.5168 - val_accuracy: 0.7396\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.5167 - val_accuracy: 0.7396\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7778 - val_loss: 0.5166 - val_accuracy: 0.7396\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.5165 - val_accuracy: 0.7396\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.5164 - val_accuracy: 0.7396\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7743 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7743 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.5155 - val_accuracy: 0.7396\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7743 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7743 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7743 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7760 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7760 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7760 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7760 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7760 - val_loss: 0.5141 - val_accuracy: 0.7396\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7795 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7812 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.5127 - val_accuracy: 0.7448\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7812 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7812 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7830 - val_loss: 0.5125 - val_accuracy: 0.7448\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7812 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7448\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7830 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7830 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7830 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7830 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7830 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7830 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7830 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7847 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7847 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.5118 - val_accuracy: 0.7448\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7847 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7847 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7830 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7847 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7847 - val_loss: 0.5116 - val_accuracy: 0.7448\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7847 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7847 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7847 - val_loss: 0.5115 - val_accuracy: 0.7448\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7847 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7865 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7882 - val_loss: 0.5114 - val_accuracy: 0.7448\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7865 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7847 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7865 - val_loss: 0.5113 - val_accuracy: 0.7448\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7865 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7865 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7882 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7865 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7882 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7882 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.5109 - val_accuracy: 0.7500\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7917 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7899 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7899 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7865 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7847 - val_loss: 0.5108 - val_accuracy: 0.7500\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7847 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7500\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7865 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7847 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7847 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7847 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7830 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7830 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7847 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7830 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.5104 - val_accuracy: 0.7448\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7847 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7847 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7847 - val_loss: 0.5103 - val_accuracy: 0.7448\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7847 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.5102 - val_accuracy: 0.7396\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7865 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7396\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7396\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7917 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7917 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7899 - val_loss: 0.5101 - val_accuracy: 0.7344\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7917 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7899 - val_loss: 0.5100 - val_accuracy: 0.7344\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7899 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7344\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7934 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.5099 - val_accuracy: 0.7396\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7934 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7917 - val_loss: 0.5098 - val_accuracy: 0.7396\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7899 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7917 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5097 - val_accuracy: 0.7396\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7917 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7396\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7951 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7934 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7934 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7969 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7951 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7969 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7969 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7951 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7934 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7969 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7934 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7951 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7951 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7969 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7969 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7986 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7986 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7986 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8003 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8021 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8003 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8003 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8003 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8003 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8003 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8038 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8021 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.8038 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8038 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8021 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7396\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7396\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8038 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8038 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8038 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8056 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8038 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8038 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8038 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8021 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8038 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8038 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.8038 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8038 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8038 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8021 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8038 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.8021 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8038 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8038 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8038 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.8038 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8021 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8038 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8021 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8038 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8038 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8038 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8038 - val_loss: 0.5075 - val_accuracy: 0.7448\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.8038 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7448\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7448\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7448\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8021 - val_loss: 0.5071 - val_accuracy: 0.7448\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8021 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8021 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.8021 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8021 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8021 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8021 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8021 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8021 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8021 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8021 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8021 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8021 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8021 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8021 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8021 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8021 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8003 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8021 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8021 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8021 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8003 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8021 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.8021 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5062 - val_accuracy: 0.7396\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8021 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8003 - val_loss: 0.5061 - val_accuracy: 0.7396\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.8021 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7986 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.8003 - val_loss: 0.5060 - val_accuracy: 0.7396\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8003 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5059 - val_accuracy: 0.7396\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.5058 - val_accuracy: 0.7396\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7396\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5056 - val_accuracy: 0.7396\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7969 - val_loss: 0.5054 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7951 - val_loss: 0.5053 - val_accuracy: 0.7396\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5054 - val_accuracy: 0.7396\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7396\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5055 - val_accuracy: 0.7448\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7934 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5056 - val_accuracy: 0.7448\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7934 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7969 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5057 - val_accuracy: 0.7448\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7934 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7934 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7934 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.5058 - val_accuracy: 0.7448\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7951 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7934 - val_loss: 0.5059 - val_accuracy: 0.7448\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7934 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7934 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7934 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7951 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5060 - val_accuracy: 0.7448\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7934 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7934 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7969 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7934 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7951 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7951 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7969 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7951 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7951 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5063 - val_accuracy: 0.7448\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5066 - val_accuracy: 0.7500\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5067 - val_accuracy: 0.7500\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7969 - val_loss: 0.5068 - val_accuracy: 0.7500\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7986 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5071 - val_accuracy: 0.7552\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7986 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8003 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8021 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8003 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8021 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8003 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8021 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7986 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8021 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7986 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7986 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7986 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7986 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7986 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7500\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7969 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5080 - val_accuracy: 0.7500\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8021 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5082 - val_accuracy: 0.7500\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5083 - val_accuracy: 0.7500\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8003 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5084 - val_accuracy: 0.7500\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8003 - val_loss: 0.5085 - val_accuracy: 0.7500\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8056 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5087 - val_accuracy: 0.7500\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8056 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8021 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8038 - val_loss: 0.5086 - val_accuracy: 0.7500\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8003 - val_loss: 0.5086 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "#  Adam, SGD, RMSprop\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
