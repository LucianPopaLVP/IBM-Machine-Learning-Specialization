{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\KonuTech\\\\Downloads\\\\40EDOJTnTFmBAziU5xxZqw_35cab0f65113443aa1b22af9d40d2b41_05d_LAB_Keras_Intro'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>27.7</td>\n",
       "      <td>0.299</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7</td>\n",
       "      <td>106</td>\n",
       "      <td>92</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.235</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.805</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>0.525</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>4</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.212</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "182               1                       0              74              20   \n",
       "42                7                     106              92              18   \n",
       "221               2                     158              90               0   \n",
       "513               2                      91              62               0   \n",
       "604               4                     183               0               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "182       23  27.7              0.299   21             0  \n",
       "42         0  22.7              0.235   48             0  \n",
       "221        0  31.6              0.805   66             1  \n",
       "513        0  27.3              0.525   22             0  \n",
       "604        0  28.4              0.212   36             1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.771\n",
      "roc-auc is 0.825\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 27ms/step - loss: 0.6345 - accuracy: 0.6771 - val_loss: 0.6581 - val_accuracy: 0.6406\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6513 - val_loss: 0.6572 - val_accuracy: 0.6406\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.6519 - val_loss: 0.6564 - val_accuracy: 0.6406\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6871 - val_loss: 0.6555 - val_accuracy: 0.6406\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.6950 - val_loss: 0.6546 - val_accuracy: 0.6406\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.6621 - val_loss: 0.6538 - val_accuracy: 0.6406\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.6667 - val_loss: 0.6530 - val_accuracy: 0.6406\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.6826 - val_loss: 0.6521 - val_accuracy: 0.6406\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6357 - accuracy: 0.6765 - val_loss: 0.6513 - val_accuracy: 0.6406\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6592 - val_loss: 0.6505 - val_accuracy: 0.6406\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6811 - val_loss: 0.6497 - val_accuracy: 0.6406\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.7000 - val_loss: 0.6489 - val_accuracy: 0.6406\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.6843 - val_loss: 0.6481 - val_accuracy: 0.6406\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6499 - val_loss: 0.6473 - val_accuracy: 0.6458\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6614 - val_loss: 0.6466 - val_accuracy: 0.6458\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.7032 - val_loss: 0.6458 - val_accuracy: 0.6458\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6697 - val_loss: 0.6450 - val_accuracy: 0.6458\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.6839 - val_loss: 0.6443 - val_accuracy: 0.6458\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6842 - val_loss: 0.6435 - val_accuracy: 0.6458\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6243 - accuracy: 0.6689 - val_loss: 0.6427 - val_accuracy: 0.6458\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.6512 - val_loss: 0.6420 - val_accuracy: 0.6458\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.6868 - val_loss: 0.6413 - val_accuracy: 0.6458\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.6615 - val_loss: 0.6405 - val_accuracy: 0.6458\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.6532 - val_loss: 0.6398 - val_accuracy: 0.6458\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6414 - accuracy: 0.6565 - val_loss: 0.6391 - val_accuracy: 0.6458\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6984 - val_loss: 0.6383 - val_accuracy: 0.6458\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6775 - val_loss: 0.6376 - val_accuracy: 0.6458\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6342 - accuracy: 0.6674 - val_loss: 0.6369 - val_accuracy: 0.6458\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.6634 - val_loss: 0.6362 - val_accuracy: 0.6458\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6288 - accuracy: 0.6731 - val_loss: 0.6355 - val_accuracy: 0.6458\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6270 - accuracy: 0.6644 - val_loss: 0.6348 - val_accuracy: 0.6458\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6359 - accuracy: 0.6589 - val_loss: 0.6341 - val_accuracy: 0.6458\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.6552 - val_loss: 0.6334 - val_accuracy: 0.6458\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6742 - val_loss: 0.6327 - val_accuracy: 0.6458\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6257 - accuracy: 0.6626 - val_loss: 0.6320 - val_accuracy: 0.6458\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6721 - val_loss: 0.6313 - val_accuracy: 0.6458\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6590 - val_loss: 0.6307 - val_accuracy: 0.6458\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6721 - val_loss: 0.6300 - val_accuracy: 0.6458\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6636 - val_loss: 0.6293 - val_accuracy: 0.6458\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.6668 - val_loss: 0.6286 - val_accuracy: 0.6406\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.6672 - val_loss: 0.6280 - val_accuracy: 0.6406\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6703 - val_loss: 0.6273 - val_accuracy: 0.6406\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.7101 - val_loss: 0.6266 - val_accuracy: 0.6406\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.6480 - val_loss: 0.6260 - val_accuracy: 0.6406\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.6480 - val_loss: 0.6253 - val_accuracy: 0.6406\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.6789 - val_loss: 0.6247 - val_accuracy: 0.6406\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.6685 - val_loss: 0.6240 - val_accuracy: 0.6406\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6740 - val_loss: 0.6234 - val_accuracy: 0.6406\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.6910 - val_loss: 0.6227 - val_accuracy: 0.6406\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6800 - val_loss: 0.6221 - val_accuracy: 0.6406\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6702 - val_loss: 0.6214 - val_accuracy: 0.6458\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6856 - val_loss: 0.6208 - val_accuracy: 0.6458\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.6671 - val_loss: 0.6202 - val_accuracy: 0.6458\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.6712 - val_loss: 0.6195 - val_accuracy: 0.6458\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7021 - val_loss: 0.6189 - val_accuracy: 0.6458\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.7166 - val_loss: 0.6183 - val_accuracy: 0.6458\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6130 - accuracy: 0.6559 - val_loss: 0.6177 - val_accuracy: 0.6458\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5999 - accuracy: 0.6884 - val_loss: 0.6170 - val_accuracy: 0.6458\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6051 - accuracy: 0.6716 - val_loss: 0.6164 - val_accuracy: 0.6458\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6126 - accuracy: 0.6666 - val_loss: 0.6158 - val_accuracy: 0.6458\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.6918 - val_loss: 0.6152 - val_accuracy: 0.6458\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.6666 - val_loss: 0.6146 - val_accuracy: 0.6458\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.6782 - val_loss: 0.6140 - val_accuracy: 0.6458\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.6667 - val_loss: 0.6134 - val_accuracy: 0.6458\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.6819 - val_loss: 0.6127 - val_accuracy: 0.6458\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.6539 - val_loss: 0.6121 - val_accuracy: 0.6458\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.6645 - val_loss: 0.6115 - val_accuracy: 0.6458\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5899 - accuracy: 0.6886 - val_loss: 0.6110 - val_accuracy: 0.6458\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5843 - accuracy: 0.6997 - val_loss: 0.6104 - val_accuracy: 0.6458\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6005 - accuracy: 0.6831 - val_loss: 0.6098 - val_accuracy: 0.6458\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6826 - val_loss: 0.6092 - val_accuracy: 0.6458\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6048 - accuracy: 0.6745 - val_loss: 0.6086 - val_accuracy: 0.6458\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6753 - val_loss: 0.6080 - val_accuracy: 0.6458\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.6724 - val_loss: 0.6074 - val_accuracy: 0.6458\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.6930 - val_loss: 0.6068 - val_accuracy: 0.6458\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6473 - val_loss: 0.6063 - val_accuracy: 0.6458\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.6921 - val_loss: 0.6057 - val_accuracy: 0.6458\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6787 - val_loss: 0.6051 - val_accuracy: 0.6510\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6845 - val_loss: 0.6045 - val_accuracy: 0.6510\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7034 - val_loss: 0.6039 - val_accuracy: 0.6510\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6804 - val_loss: 0.6034 - val_accuracy: 0.6562\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7068 - val_loss: 0.6028 - val_accuracy: 0.6615\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6868 - val_loss: 0.6022 - val_accuracy: 0.6615\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.6910 - val_loss: 0.6017 - val_accuracy: 0.6562\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6026 - accuracy: 0.6465 - val_loss: 0.6011 - val_accuracy: 0.6562\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.7206 - val_loss: 0.6005 - val_accuracy: 0.6615\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.6740 - val_loss: 0.6000 - val_accuracy: 0.6615\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.6780 - val_loss: 0.5994 - val_accuracy: 0.6615\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.6954 - val_loss: 0.5989 - val_accuracy: 0.6615\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.6596 - val_loss: 0.5983 - val_accuracy: 0.6615\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6919 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5641 - accuracy: 0.7197 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6629 - val_loss: 0.5967 - val_accuracy: 0.6667\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6854 - val_loss: 0.5961 - val_accuracy: 0.6667\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6047 - accuracy: 0.6430 - val_loss: 0.5956 - val_accuracy: 0.6667\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6700 - val_loss: 0.5951 - val_accuracy: 0.6667\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5978 - accuracy: 0.6677 - val_loss: 0.5945 - val_accuracy: 0.6719\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6751 - val_loss: 0.5940 - val_accuracy: 0.6719\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6729 - val_loss: 0.5935 - val_accuracy: 0.6719\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5822 - accuracy: 0.6814 - val_loss: 0.5929 - val_accuracy: 0.6719\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.6641 - val_loss: 0.5924 - val_accuracy: 0.6719\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5768 - accuracy: 0.6973 - val_loss: 0.5919 - val_accuracy: 0.6719\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6636 - val_loss: 0.5913 - val_accuracy: 0.6719\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5918 - accuracy: 0.6645 - val_loss: 0.5908 - val_accuracy: 0.6719\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6636 - val_loss: 0.5903 - val_accuracy: 0.6719\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5716 - accuracy: 0.6858 - val_loss: 0.5898 - val_accuracy: 0.6771\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.6833 - val_loss: 0.5892 - val_accuracy: 0.6771\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.6831 - val_loss: 0.5887 - val_accuracy: 0.6771\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5900 - accuracy: 0.6751 - val_loss: 0.5882 - val_accuracy: 0.6771\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.6774 - val_loss: 0.5877 - val_accuracy: 0.6771\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.6941 - val_loss: 0.5872 - val_accuracy: 0.6771\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7240 - val_loss: 0.5867 - val_accuracy: 0.6771\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.6962 - val_loss: 0.5862 - val_accuracy: 0.6771\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.6875 - val_loss: 0.5856 - val_accuracy: 0.6771\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5732 - accuracy: 0.6909 - val_loss: 0.5851 - val_accuracy: 0.6771\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5661 - accuracy: 0.6921 - val_loss: 0.5846 - val_accuracy: 0.6823\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.7020 - val_loss: 0.5841 - val_accuracy: 0.6823\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.6765 - val_loss: 0.5836 - val_accuracy: 0.6823\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.6980 - val_loss: 0.5831 - val_accuracy: 0.6823\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5787 - accuracy: 0.6853 - val_loss: 0.5826 - val_accuracy: 0.6823\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7221 - val_loss: 0.5821 - val_accuracy: 0.6823\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7103 - val_loss: 0.5816 - val_accuracy: 0.6823\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5579 - accuracy: 0.7133 - val_loss: 0.5812 - val_accuracy: 0.6823\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7094 - val_loss: 0.5807 - val_accuracy: 0.6823\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5785 - accuracy: 0.6864 - val_loss: 0.5802 - val_accuracy: 0.6823\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7084 - val_loss: 0.5797 - val_accuracy: 0.6823\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.7070 - val_loss: 0.5792 - val_accuracy: 0.6823\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5714 - accuracy: 0.6890 - val_loss: 0.5787 - val_accuracy: 0.6823\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.6825 - val_loss: 0.5782 - val_accuracy: 0.6823\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.6882 - val_loss: 0.5778 - val_accuracy: 0.6927\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7366 - val_loss: 0.5773 - val_accuracy: 0.6927\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7081 - val_loss: 0.5768 - val_accuracy: 0.6927\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7043 - val_loss: 0.5763 - val_accuracy: 0.6927\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.7162 - val_loss: 0.5759 - val_accuracy: 0.6927\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7513 - val_loss: 0.5754 - val_accuracy: 0.6927\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7157 - val_loss: 0.5749 - val_accuracy: 0.6927\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6759 - val_loss: 0.5745 - val_accuracy: 0.6927\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7020 - val_loss: 0.5740 - val_accuracy: 0.6927\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7142 - val_loss: 0.5735 - val_accuracy: 0.6927\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.7197 - val_loss: 0.5731 - val_accuracy: 0.6927\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5564 - accuracy: 0.7227 - val_loss: 0.5726 - val_accuracy: 0.6927\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5656 - accuracy: 0.7065 - val_loss: 0.5721 - val_accuracy: 0.6927\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.6923 - val_loss: 0.5717 - val_accuracy: 0.6979\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7264 - val_loss: 0.5712 - val_accuracy: 0.7031\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7249 - val_loss: 0.5708 - val_accuracy: 0.7083\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5535 - accuracy: 0.7250 - val_loss: 0.5703 - val_accuracy: 0.7083\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7257 - val_loss: 0.5699 - val_accuracy: 0.7083\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.6978 - val_loss: 0.5694 - val_accuracy: 0.7135\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.7024 - val_loss: 0.5690 - val_accuracy: 0.7135\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7145 - val_loss: 0.5685 - val_accuracy: 0.7135\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7178 - val_loss: 0.5681 - val_accuracy: 0.7188\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.7320 - val_loss: 0.5677 - val_accuracy: 0.7135\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.7387 - val_loss: 0.5672 - val_accuracy: 0.7135\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7225 - val_loss: 0.5668 - val_accuracy: 0.7135\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7201 - val_loss: 0.5663 - val_accuracy: 0.7135\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7118 - val_loss: 0.5659 - val_accuracy: 0.7135\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7287 - val_loss: 0.5655 - val_accuracy: 0.7188\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7268 - val_loss: 0.5650 - val_accuracy: 0.7188\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7467 - val_loss: 0.5646 - val_accuracy: 0.7188\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.7403 - val_loss: 0.5642 - val_accuracy: 0.7188\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5681 - accuracy: 0.7140 - val_loss: 0.5638 - val_accuracy: 0.7188\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5663 - accuracy: 0.7227 - val_loss: 0.5633 - val_accuracy: 0.7135\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7238 - val_loss: 0.5629 - val_accuracy: 0.7135\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7123 - val_loss: 0.5625 - val_accuracy: 0.7135\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7232 - val_loss: 0.5621 - val_accuracy: 0.7135\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7266 - val_loss: 0.5617 - val_accuracy: 0.7135\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.6946 - val_loss: 0.5612 - val_accuracy: 0.7135\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7377 - val_loss: 0.5608 - val_accuracy: 0.7135\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5511 - accuracy: 0.7371 - val_loss: 0.5604 - val_accuracy: 0.7135\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7361 - val_loss: 0.5600 - val_accuracy: 0.7135\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7262 - val_loss: 0.5596 - val_accuracy: 0.7135\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7420 - val_loss: 0.5592 - val_accuracy: 0.7135\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5524 - accuracy: 0.7368 - val_loss: 0.5588 - val_accuracy: 0.7135\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5288 - accuracy: 0.7511 - val_loss: 0.5584 - val_accuracy: 0.7135\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5530 - accuracy: 0.7352 - val_loss: 0.5580 - val_accuracy: 0.7135\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7605 - val_loss: 0.5576 - val_accuracy: 0.7135\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7575 - val_loss: 0.5572 - val_accuracy: 0.7135\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7141 - val_loss: 0.5568 - val_accuracy: 0.7135\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7479 - val_loss: 0.5564 - val_accuracy: 0.7135\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7323 - val_loss: 0.5560 - val_accuracy: 0.7135\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7264 - val_loss: 0.5556 - val_accuracy: 0.7135\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7344 - val_loss: 0.5552 - val_accuracy: 0.7135\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7688 - val_loss: 0.5548 - val_accuracy: 0.7135\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7220 - val_loss: 0.5544 - val_accuracy: 0.7188\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5593 - accuracy: 0.7313 - val_loss: 0.5540 - val_accuracy: 0.7188\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5343 - accuracy: 0.7523 - val_loss: 0.5537 - val_accuracy: 0.7240\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5493 - accuracy: 0.7213 - val_loss: 0.5533 - val_accuracy: 0.7292\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7236 - val_loss: 0.5529 - val_accuracy: 0.7292\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7283 - val_loss: 0.5525 - val_accuracy: 0.7292\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7467 - val_loss: 0.5521 - val_accuracy: 0.7292\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7624 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7448 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7376 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5295 - accuracy: 0.7505 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7634 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5309 - accuracy: 0.7615 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7219 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.7629 - val_loss: 0.5492 - val_accuracy: 0.7396\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7393 - val_loss: 0.5488 - val_accuracy: 0.7396\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7462 - val_loss: 0.5484 - val_accuracy: 0.7448\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4293835 ],\n",
       "       [0.47740328],\n",
       "       [0.309299  ],\n",
       "       [0.24866042],\n",
       "       [0.30857253],\n",
       "       [0.46594724],\n",
       "       [0.2361688 ],\n",
       "       [0.31670395],\n",
       "       [0.59012824],\n",
       "       [0.27890435]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.745\n",
      "roc-auc is 0.813\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b85c6f2048>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5371 - accuracy: 0.7517 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5368 - accuracy: 0.7500 - val_loss: 0.5477 - val_accuracy: 0.7448\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7552 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7552 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7552 - val_loss: 0.5467 - val_accuracy: 0.7448\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7552 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.7535 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7535 - val_loss: 0.5456 - val_accuracy: 0.7448\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7535 - val_loss: 0.5453 - val_accuracy: 0.7448\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7552 - val_loss: 0.5449 - val_accuracy: 0.7448\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7552 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5331 - accuracy: 0.7535 - val_loss: 0.5442 - val_accuracy: 0.7552\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7535 - val_loss: 0.5439 - val_accuracy: 0.7552\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7535 - val_loss: 0.5436 - val_accuracy: 0.7552\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7535 - val_loss: 0.5432 - val_accuracy: 0.7552\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7552 - val_loss: 0.5429 - val_accuracy: 0.7552\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7552 - val_loss: 0.5426 - val_accuracy: 0.7552\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7552 - val_loss: 0.5422 - val_accuracy: 0.7552\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7535 - val_loss: 0.5419 - val_accuracy: 0.7552\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7552 - val_loss: 0.5416 - val_accuracy: 0.7552\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7552 - val_loss: 0.5412 - val_accuracy: 0.7656\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7535 - val_loss: 0.5409 - val_accuracy: 0.7656\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5293 - accuracy: 0.7552 - val_loss: 0.5406 - val_accuracy: 0.7656\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7552 - val_loss: 0.5403 - val_accuracy: 0.7656\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.7517 - val_loss: 0.5399 - val_accuracy: 0.7656\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7517 - val_loss: 0.5396 - val_accuracy: 0.7656\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5280 - accuracy: 0.7535 - val_loss: 0.5393 - val_accuracy: 0.7656\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7552 - val_loss: 0.5390 - val_accuracy: 0.7656\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7552 - val_loss: 0.5387 - val_accuracy: 0.7656\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7552 - val_loss: 0.5384 - val_accuracy: 0.7656\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7535 - val_loss: 0.5380 - val_accuracy: 0.7656\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7535 - val_loss: 0.5377 - val_accuracy: 0.7708\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5260 - accuracy: 0.7517 - val_loss: 0.5374 - val_accuracy: 0.7708\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7517 - val_loss: 0.5371 - val_accuracy: 0.7708\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7500 - val_loss: 0.5368 - val_accuracy: 0.7708\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7500 - val_loss: 0.5365 - val_accuracy: 0.7708\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7500 - val_loss: 0.5362 - val_accuracy: 0.7708\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7483 - val_loss: 0.5359 - val_accuracy: 0.7708\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7483 - val_loss: 0.5356 - val_accuracy: 0.7708\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5238 - accuracy: 0.7483 - val_loss: 0.5353 - val_accuracy: 0.7708\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5350 - val_accuracy: 0.7760\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7483 - val_loss: 0.5347 - val_accuracy: 0.7760\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7500 - val_loss: 0.5344 - val_accuracy: 0.7760\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7500 - val_loss: 0.5341 - val_accuracy: 0.7760\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7517 - val_loss: 0.5338 - val_accuracy: 0.7760\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7517 - val_loss: 0.5335 - val_accuracy: 0.7760\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7517 - val_loss: 0.5333 - val_accuracy: 0.7760\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7500 - val_loss: 0.5330 - val_accuracy: 0.7760\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.5327 - val_accuracy: 0.7760\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7517 - val_loss: 0.5324 - val_accuracy: 0.7708\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7517 - val_loss: 0.5321 - val_accuracy: 0.7708\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7500 - val_loss: 0.5318 - val_accuracy: 0.7708\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7517 - val_loss: 0.5316 - val_accuracy: 0.7708\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7517 - val_loss: 0.5313 - val_accuracy: 0.7708\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7517 - val_loss: 0.5310 - val_accuracy: 0.7812\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.7517 - val_loss: 0.5307 - val_accuracy: 0.7812\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.7517 - val_loss: 0.5305 - val_accuracy: 0.7812\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7517 - val_loss: 0.5302 - val_accuracy: 0.7812\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7552 - val_loss: 0.5299 - val_accuracy: 0.7812\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7552 - val_loss: 0.5296 - val_accuracy: 0.7812\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7569 - val_loss: 0.5294 - val_accuracy: 0.7812\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7569 - val_loss: 0.5291 - val_accuracy: 0.7865\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7569 - val_loss: 0.5288 - val_accuracy: 0.7812\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7569 - val_loss: 0.5286 - val_accuracy: 0.7812\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5164 - accuracy: 0.7569 - val_loss: 0.5283 - val_accuracy: 0.7812\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7569 - val_loss: 0.5281 - val_accuracy: 0.7812\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7569 - val_loss: 0.5278 - val_accuracy: 0.7812\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7587 - val_loss: 0.5275 - val_accuracy: 0.7812\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7587 - val_loss: 0.5273 - val_accuracy: 0.7812\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.7587 - val_loss: 0.5270 - val_accuracy: 0.7812\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7604 - val_loss: 0.5268 - val_accuracy: 0.7812\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7604 - val_loss: 0.5265 - val_accuracy: 0.7812\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7622 - val_loss: 0.5263 - val_accuracy: 0.7812\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.7622 - val_loss: 0.5260 - val_accuracy: 0.7812\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7622 - val_loss: 0.5258 - val_accuracy: 0.7812\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7622 - val_loss: 0.5255 - val_accuracy: 0.7812\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7604 - val_loss: 0.5253 - val_accuracy: 0.7812\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7604 - val_loss: 0.5250 - val_accuracy: 0.7812\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7622 - val_loss: 0.5248 - val_accuracy: 0.7812\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7622 - val_loss: 0.5246 - val_accuracy: 0.7812\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7622 - val_loss: 0.5243 - val_accuracy: 0.7812\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7622 - val_loss: 0.5241 - val_accuracy: 0.7812\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7622 - val_loss: 0.5238 - val_accuracy: 0.7812\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7604 - val_loss: 0.5236 - val_accuracy: 0.7812\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7604 - val_loss: 0.5234 - val_accuracy: 0.7812\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7604 - val_loss: 0.5231 - val_accuracy: 0.7812\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7622 - val_loss: 0.5229 - val_accuracy: 0.7812\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7622 - val_loss: 0.5227 - val_accuracy: 0.7812\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7622 - val_loss: 0.5224 - val_accuracy: 0.7812\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7622 - val_loss: 0.5222 - val_accuracy: 0.7812\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5096 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7812\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7812\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7812\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7622 - val_loss: 0.5213 - val_accuracy: 0.7812\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7622 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7622 - val_loss: 0.5209 - val_accuracy: 0.7812\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7622 - val_loss: 0.5207 - val_accuracy: 0.7865\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7622 - val_loss: 0.5204 - val_accuracy: 0.7865\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7622 - val_loss: 0.5202 - val_accuracy: 0.7812\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.7639 - val_loss: 0.5200 - val_accuracy: 0.7812\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7639 - val_loss: 0.5198 - val_accuracy: 0.7812\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7639 - val_loss: 0.5196 - val_accuracy: 0.7812\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7656 - val_loss: 0.5194 - val_accuracy: 0.7812\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7622 - val_loss: 0.5191 - val_accuracy: 0.7812\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7622 - val_loss: 0.5189 - val_accuracy: 0.7812\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7656 - val_loss: 0.5187 - val_accuracy: 0.7812\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7622 - val_loss: 0.5185 - val_accuracy: 0.7812\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7622 - val_loss: 0.5183 - val_accuracy: 0.7812\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7622 - val_loss: 0.5181 - val_accuracy: 0.7812\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7604 - val_loss: 0.5179 - val_accuracy: 0.7812\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5049 - accuracy: 0.7622 - val_loss: 0.5177 - val_accuracy: 0.7812\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7639 - val_loss: 0.5175 - val_accuracy: 0.7812\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7604 - val_loss: 0.5173 - val_accuracy: 0.7812\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7639 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7639 - val_loss: 0.5169 - val_accuracy: 0.7812\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5038 - accuracy: 0.7639 - val_loss: 0.5167 - val_accuracy: 0.7865\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7639 - val_loss: 0.5165 - val_accuracy: 0.7865\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7639 - val_loss: 0.5163 - val_accuracy: 0.7865\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7639 - val_loss: 0.5161 - val_accuracy: 0.7865\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7639 - val_loss: 0.5159 - val_accuracy: 0.7865\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7639 - val_loss: 0.5157 - val_accuracy: 0.7865\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7639 - val_loss: 0.5155 - val_accuracy: 0.7865\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7656 - val_loss: 0.5154 - val_accuracy: 0.7917\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7656 - val_loss: 0.5152 - val_accuracy: 0.7865\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7674 - val_loss: 0.5150 - val_accuracy: 0.7865\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.7674 - val_loss: 0.5148 - val_accuracy: 0.7865\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.7674 - val_loss: 0.5146 - val_accuracy: 0.7865\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7674 - val_loss: 0.5144 - val_accuracy: 0.7865\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7674 - val_loss: 0.5143 - val_accuracy: 0.7865\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7674 - val_loss: 0.5141 - val_accuracy: 0.7865\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7674 - val_loss: 0.5139 - val_accuracy: 0.7865\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7674 - val_loss: 0.5137 - val_accuracy: 0.7865\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7674 - val_loss: 0.5135 - val_accuracy: 0.7865\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7656 - val_loss: 0.5134 - val_accuracy: 0.7865\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7656 - val_loss: 0.5132 - val_accuracy: 0.7812\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7656 - val_loss: 0.5130 - val_accuracy: 0.7812\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7674 - val_loss: 0.5128 - val_accuracy: 0.7812\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7656 - val_loss: 0.5127 - val_accuracy: 0.7812\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7674 - val_loss: 0.5125 - val_accuracy: 0.7812\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.7656 - val_loss: 0.5123 - val_accuracy: 0.7812\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7691 - val_loss: 0.5121 - val_accuracy: 0.7812\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.7674 - val_loss: 0.5120 - val_accuracy: 0.7812\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7691 - val_loss: 0.5118 - val_accuracy: 0.7812\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7691 - val_loss: 0.5116 - val_accuracy: 0.7812\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7691 - val_loss: 0.5115 - val_accuracy: 0.7812\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.7691 - val_loss: 0.5113 - val_accuracy: 0.7812\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.7691 - val_loss: 0.5111 - val_accuracy: 0.7812\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7691 - val_loss: 0.5110 - val_accuracy: 0.7812\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7691 - val_loss: 0.5108 - val_accuracy: 0.7812\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7691 - val_loss: 0.5107 - val_accuracy: 0.7812\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7691 - val_loss: 0.5105 - val_accuracy: 0.7812\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7691 - val_loss: 0.5103 - val_accuracy: 0.7812\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7691 - val_loss: 0.5102 - val_accuracy: 0.7812\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7708 - val_loss: 0.5100 - val_accuracy: 0.7812\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7708 - val_loss: 0.5099 - val_accuracy: 0.7812\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7708 - val_loss: 0.5097 - val_accuracy: 0.7760\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7691 - val_loss: 0.5096 - val_accuracy: 0.7760\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7691 - val_loss: 0.5094 - val_accuracy: 0.7760\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7691 - val_loss: 0.5093 - val_accuracy: 0.7760\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7708 - val_loss: 0.5091 - val_accuracy: 0.7760\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7708 - val_loss: 0.5090 - val_accuracy: 0.7760\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7691 - val_loss: 0.5088 - val_accuracy: 0.7760\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7674 - val_loss: 0.5087 - val_accuracy: 0.7760\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7691 - val_loss: 0.5085 - val_accuracy: 0.7760\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7708 - val_loss: 0.5084 - val_accuracy: 0.7760\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7691 - val_loss: 0.5082 - val_accuracy: 0.7760\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7760\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7743 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7743 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7743 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7743 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4928 - accuracy: 0.7743 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7743 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7743 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7743 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7743 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7743 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7708\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7743 - val_loss: 0.5060 - val_accuracy: 0.7708\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7743 - val_loss: 0.5059 - val_accuracy: 0.7708\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7708\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7726 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7726 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7726 - val_loss: 0.5052 - val_accuracy: 0.7708\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7726 - val_loss: 0.5051 - val_accuracy: 0.7708\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7726 - val_loss: 0.5050 - val_accuracy: 0.7708\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7726 - val_loss: 0.5049 - val_accuracy: 0.7708\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7726 - val_loss: 0.5047 - val_accuracy: 0.7708\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7726 - val_loss: 0.5046 - val_accuracy: 0.7708\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7726 - val_loss: 0.5045 - val_accuracy: 0.7708\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7708 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7708 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7708 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7708 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7708 - val_loss: 0.5039 - val_accuracy: 0.7708\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7708\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7708\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7708\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7708\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7708\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.7708 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7708 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7708 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7708 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7708 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7726 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7726 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7726 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7726 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7743 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7743 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7743 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7743 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7743 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.7743 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7743 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.7743 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.7743 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7743 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7743 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7743 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7743 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7743 - val_loss: 0.4997 - val_accuracy: 0.7708\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7743 - val_loss: 0.4996 - val_accuracy: 0.7708\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7743 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7743 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4832 - accuracy: 0.7743 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7743 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7743 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7743 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7743 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7743 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7743 - val_loss: 0.4980 - val_accuracy: 0.7760\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7743 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7743 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7743 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7743 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7743 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7726 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7726 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7726 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7726 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7726 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7726 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7726 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7726 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7726 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7760 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7743 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7743 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7656\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7656\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7656\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7778 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7778 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7778 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7778 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7760 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7760 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7743 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7552\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.4907 - val_accuracy: 0.7552\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.4905 - val_accuracy: 0.7552\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7552\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7552\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7552\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7552\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7552\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7552\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7743 - val_loss: 0.4898 - val_accuracy: 0.7552\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4897 - val_accuracy: 0.7552\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7552\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4895 - val_accuracy: 0.7552\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7552\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7726 - val_loss: 0.4893 - val_accuracy: 0.7552\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4892 - val_accuracy: 0.7552\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7552\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4891 - val_accuracy: 0.7500\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7500\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4889 - val_accuracy: 0.7500\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7500\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7500\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7552\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7760 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7552\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7760 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7552\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7552\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7552\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7552\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7656\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4879 - val_accuracy: 0.7708\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4880 - val_accuracy: 0.7708\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7708\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4881 - val_accuracy: 0.7656\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4882 - val_accuracy: 0.7656\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4883 - val_accuracy: 0.7656\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7656\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7795 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4885 - val_accuracy: 0.7656\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7778 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4886 - val_accuracy: 0.7656\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7656\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4887 - val_accuracy: 0.7604\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7795 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7812 - val_loss: 0.4888 - val_accuracy: 0.7604\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b85d8d7fc8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.6197 - val_loss: 0.6809 - val_accuracy: 0.6302\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.6024 - val_loss: 0.6768 - val_accuracy: 0.6354\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.6152 - val_loss: 0.6729 - val_accuracy: 0.6354\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6871 - accuracy: 0.6035 - val_loss: 0.6692 - val_accuracy: 0.6302\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6350 - val_loss: 0.6655 - val_accuracy: 0.6302\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6216 - val_loss: 0.6620 - val_accuracy: 0.6354\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6267 - val_loss: 0.6586 - val_accuracy: 0.6354\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.6584 - val_loss: 0.6553 - val_accuracy: 0.6354\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.6453 - val_loss: 0.6521 - val_accuracy: 0.6354\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.6350 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6360 - val_loss: 0.6460 - val_accuracy: 0.6406\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6579 - accuracy: 0.6238 - val_loss: 0.6431 - val_accuracy: 0.6406\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6020 - val_loss: 0.6403 - val_accuracy: 0.6406\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.6310 - val_loss: 0.6375 - val_accuracy: 0.6406\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6396 - val_loss: 0.6349 - val_accuracy: 0.6406\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6328 - val_loss: 0.6323 - val_accuracy: 0.6458\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6578 - val_loss: 0.6297 - val_accuracy: 0.6458\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.6661 - val_loss: 0.6273 - val_accuracy: 0.6458\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.6427 - val_loss: 0.6249 - val_accuracy: 0.6458\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.6320 - val_loss: 0.6226 - val_accuracy: 0.6510\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6599 - val_loss: 0.6204 - val_accuracy: 0.6510\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6423 - val_loss: 0.6182 - val_accuracy: 0.6510\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.6415 - val_loss: 0.6161 - val_accuracy: 0.6562\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6012 - accuracy: 0.6652 - val_loss: 0.6140 - val_accuracy: 0.6510\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.6597 - val_loss: 0.6120 - val_accuracy: 0.6510\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6672 - val_loss: 0.6099 - val_accuracy: 0.6510\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5990 - accuracy: 0.6657 - val_loss: 0.6080 - val_accuracy: 0.6562\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.6832 - val_loss: 0.6061 - val_accuracy: 0.6562\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6060 - accuracy: 0.6456 - val_loss: 0.6042 - val_accuracy: 0.6615\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5916 - accuracy: 0.6667 - val_loss: 0.6024 - val_accuracy: 0.6615\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.6502 - val_loss: 0.6006 - val_accuracy: 0.6615\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6640 - val_loss: 0.5989 - val_accuracy: 0.6719\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6463 - val_loss: 0.5971 - val_accuracy: 0.6719\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6691 - val_loss: 0.5954 - val_accuracy: 0.6771\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6849 - val_loss: 0.5938 - val_accuracy: 0.6771\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.6757 - val_loss: 0.5922 - val_accuracy: 0.6771\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.6957 - val_loss: 0.5906 - val_accuracy: 0.6771\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6458 - val_loss: 0.5890 - val_accuracy: 0.6771\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6002 - accuracy: 0.6537 - val_loss: 0.5875 - val_accuracy: 0.6823\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.6896 - val_loss: 0.5860 - val_accuracy: 0.6979\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.6963 - val_loss: 0.5845 - val_accuracy: 0.7031\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.6906 - val_loss: 0.5831 - val_accuracy: 0.6927\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.6956 - val_loss: 0.5817 - val_accuracy: 0.6979\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5711 - accuracy: 0.6903 - val_loss: 0.5803 - val_accuracy: 0.7083\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7050 - val_loss: 0.5790 - val_accuracy: 0.7083\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5866 - accuracy: 0.6850 - val_loss: 0.5776 - val_accuracy: 0.7135\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7102 - val_loss: 0.5763 - val_accuracy: 0.7083\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7031 - val_loss: 0.5751 - val_accuracy: 0.7083\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7135 - val_loss: 0.5738 - val_accuracy: 0.7083\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7239 - val_loss: 0.5726 - val_accuracy: 0.7135\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7231 - val_loss: 0.5714 - val_accuracy: 0.7135\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7018 - val_loss: 0.5702 - val_accuracy: 0.7240\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.7058 - val_loss: 0.5690 - val_accuracy: 0.7188\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7088 - val_loss: 0.5679 - val_accuracy: 0.7188\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7069 - val_loss: 0.5667 - val_accuracy: 0.7188\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7128 - val_loss: 0.5656 - val_accuracy: 0.7188\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7433 - val_loss: 0.5645 - val_accuracy: 0.7240\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7228 - val_loss: 0.5634 - val_accuracy: 0.7240\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7108 - val_loss: 0.5624 - val_accuracy: 0.7292\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7257 - val_loss: 0.5613 - val_accuracy: 0.7292\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7222 - val_loss: 0.5603 - val_accuracy: 0.7240\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.6970 - val_loss: 0.5593 - val_accuracy: 0.7240\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7220 - val_loss: 0.5584 - val_accuracy: 0.7188\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7198 - val_loss: 0.5574 - val_accuracy: 0.7188\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.6954 - val_loss: 0.5565 - val_accuracy: 0.7188\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7290 - val_loss: 0.5556 - val_accuracy: 0.7135\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7021 - val_loss: 0.5547 - val_accuracy: 0.7135\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7138 - val_loss: 0.5538 - val_accuracy: 0.7135\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7287 - val_loss: 0.5530 - val_accuracy: 0.7135\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7208 - val_loss: 0.5521 - val_accuracy: 0.7188\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.6967 - val_loss: 0.5513 - val_accuracy: 0.7188\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7343 - val_loss: 0.5504 - val_accuracy: 0.7188\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7328 - val_loss: 0.5496 - val_accuracy: 0.7188\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7381 - val_loss: 0.5488 - val_accuracy: 0.7188\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7426 - val_loss: 0.5480 - val_accuracy: 0.7188\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7291 - val_loss: 0.5472 - val_accuracy: 0.7240\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7162 - val_loss: 0.5465 - val_accuracy: 0.7240\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.7445 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7624 - val_loss: 0.5449 - val_accuracy: 0.7240\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7086 - val_loss: 0.5442 - val_accuracy: 0.7240\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7377 - val_loss: 0.5434 - val_accuracy: 0.7240\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7419 - val_loss: 0.5427 - val_accuracy: 0.7240\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7422 - val_loss: 0.5420 - val_accuracy: 0.7240\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7297 - val_loss: 0.5413 - val_accuracy: 0.7292\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.6932 - val_loss: 0.5406 - val_accuracy: 0.7292\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.6958 - val_loss: 0.5399 - val_accuracy: 0.7292\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5091 - accuracy: 0.7386 - val_loss: 0.5392 - val_accuracy: 0.7292\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7173 - val_loss: 0.5385 - val_accuracy: 0.7292\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7291 - val_loss: 0.5379 - val_accuracy: 0.7292\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7454 - val_loss: 0.5373 - val_accuracy: 0.7292\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7295 - val_loss: 0.5367 - val_accuracy: 0.7292\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7371 - val_loss: 0.5360 - val_accuracy: 0.7396\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7525 - val_loss: 0.5355 - val_accuracy: 0.7396\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7560 - val_loss: 0.5349 - val_accuracy: 0.7396\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7547 - val_loss: 0.5344 - val_accuracy: 0.7396\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7164 - val_loss: 0.5339 - val_accuracy: 0.7396\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7783 - val_loss: 0.5333 - val_accuracy: 0.7396\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7577 - val_loss: 0.5328 - val_accuracy: 0.7396\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.7156 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7295 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7229 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.6955 - val_loss: 0.5308 - val_accuracy: 0.7500\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7153 - val_loss: 0.5304 - val_accuracy: 0.7500\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7551 - val_loss: 0.5299 - val_accuracy: 0.7500\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.7551 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7514 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7528 - val_loss: 0.5286 - val_accuracy: 0.7552\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7280 - val_loss: 0.5282 - val_accuracy: 0.7552\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7671 - val_loss: 0.5278 - val_accuracy: 0.7500\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7523 - val_loss: 0.5274 - val_accuracy: 0.7552\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7418 - val_loss: 0.5270 - val_accuracy: 0.7552\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7562 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7715 - val_loss: 0.5263 - val_accuracy: 0.7552\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7658 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7345 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7519 - val_loss: 0.5251 - val_accuracy: 0.7552\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7505 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7652 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7307 - val_loss: 0.5241 - val_accuracy: 0.7500\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7559 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.7641 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7715 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7714 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7420 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7635 - val_loss: 0.5221 - val_accuracy: 0.7448\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7413 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.7449 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7590 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7698 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7775 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7505 - val_loss: 0.5204 - val_accuracy: 0.7500\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7494 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.7502 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7598 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.7675 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7350 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7447 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7400 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7563 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7740 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7497 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7909 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7417 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7462 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7532 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7590 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7460 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7937 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7841 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7668 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7511 - val_loss: 0.5158 - val_accuracy: 0.7448\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7690 - val_loss: 0.5156 - val_accuracy: 0.7448\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7695 - val_loss: 0.5154 - val_accuracy: 0.7448\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7543 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7555 - val_loss: 0.5151 - val_accuracy: 0.7448\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7873 - val_loss: 0.5149 - val_accuracy: 0.7448\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7766 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7793 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7586 - val_loss: 0.5144 - val_accuracy: 0.7448\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7523 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7647 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7809 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7663 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7655 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7699 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.8027 - val_loss: 0.5132 - val_accuracy: 0.7448\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7909 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7468 - val_loss: 0.5129 - val_accuracy: 0.7448\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7705 - val_loss: 0.5128 - val_accuracy: 0.7448\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7440 - val_loss: 0.5126 - val_accuracy: 0.7448\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7709 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7572 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7519 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7766 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7717 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7658 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7969 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7941 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7866 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7799 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7765 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7673 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7636 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7772 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.7562 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7946 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7662 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7811 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7274 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7696 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7754 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7969 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7827 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7956 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.7439 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7939 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7639 - val_loss: 0.5099 - val_accuracy: 0.7552\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7684 - val_loss: 0.5098 - val_accuracy: 0.7552\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7897 - val_loss: 0.5097 - val_accuracy: 0.7552\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7928 - val_loss: 0.5096 - val_accuracy: 0.7552\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7595 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7958 - val_loss: 0.5095 - val_accuracy: 0.7552\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.7879 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7909 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7983 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7586 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7825 - val_loss: 0.5091 - val_accuracy: 0.7552\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7818 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7818 - val_loss: 0.5090 - val_accuracy: 0.7552\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7676 - val_loss: 0.5089 - val_accuracy: 0.7552\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7878 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7790 - val_loss: 0.5088 - val_accuracy: 0.7552\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7896 - val_loss: 0.5087 - val_accuracy: 0.7552\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7834 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7960 - val_loss: 0.5086 - val_accuracy: 0.7552\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7653 - val_loss: 0.5085 - val_accuracy: 0.7552\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7775 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8127 - val_loss: 0.5084 - val_accuracy: 0.7552\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7791 - val_loss: 0.5083 - val_accuracy: 0.7552\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8017 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7794 - val_loss: 0.5082 - val_accuracy: 0.7552\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7674 - val_loss: 0.5081 - val_accuracy: 0.7552\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7772 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7902 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7603 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7727 - val_loss: 0.5079 - val_accuracy: 0.7552\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7836 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7936 - val_loss: 0.5078 - val_accuracy: 0.7552\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7592 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7840 - val_loss: 0.5077 - val_accuracy: 0.7552\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7854 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7762 - val_loss: 0.5076 - val_accuracy: 0.7552\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7838 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7825 - val_loss: 0.5075 - val_accuracy: 0.7552\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7838 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.8041 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7769 - val_loss: 0.5074 - val_accuracy: 0.7552\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7794 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7943 - val_loss: 0.5073 - val_accuracy: 0.7552\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7969 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7812 - val_loss: 0.5072 - val_accuracy: 0.7552\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8027 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7757 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7823 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7871 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7852 - val_loss: 0.5070 - val_accuracy: 0.7448\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7692 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7627 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.8136 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.8048 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7887 - val_loss: 0.5068 - val_accuracy: 0.7448\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.8087 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8008 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7872 - val_loss: 0.5067 - val_accuracy: 0.7448\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.7641 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7706 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7919 - val_loss: 0.5066 - val_accuracy: 0.7448\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7701 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7658 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7961 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4343 - accuracy: 0.8122 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7910 - val_loss: 0.5065 - val_accuracy: 0.7448\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7942 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7755 - val_loss: 0.5064 - val_accuracy: 0.7448\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7679 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7824 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7697 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7681 - val_loss: 0.5064 - val_accuracy: 0.7396\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7949 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7930 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8025 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.8246 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7852 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8041 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7775 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7797 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.8086 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7566 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7766 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7999 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7775 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.8033 - val_loss: 0.5063 - val_accuracy: 0.7396\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7882 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7777 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7980 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7842 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7867 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.8072 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7869 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7735 - val_loss: 0.5062 - val_accuracy: 0.7448\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7987 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8168 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7927 - val_loss: 0.5061 - val_accuracy: 0.7448\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7933 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.7647 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.8022 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7697 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7939 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7951 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7754 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7814 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7799 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7821 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7892 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8039 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7987 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7830 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7893 - val_loss: 0.5061 - val_accuracy: 0.7500\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7521 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7750 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7779 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7931 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7949 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8119 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8083 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7921 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.8005 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7903 - val_loss: 0.5060 - val_accuracy: 0.7500\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7935 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7650 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7940 - val_loss: 0.5059 - val_accuracy: 0.7500\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7932 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8008 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8007 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7916 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8132 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7798 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8094 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7914 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8062 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7918 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8040 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7786 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8116 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7972 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7844 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7825 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7843 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7841 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8102 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7898 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4444 - accuracy: 0.7836 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7864 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8072 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7540 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7871 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7952 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7842 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7813 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7979 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8022 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7795 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.8003 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7920 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.8022 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7998 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7878 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7916 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7930 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8035 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7767 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7936 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8143 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.8062 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.8034 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7768 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8215 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7910 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8029 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.8034 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7775 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7866 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7741 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7982 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7937 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7964 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8059 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7880 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8003 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8042 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7908 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7948 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7905 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7904 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7826 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.8097 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7710 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7747 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7791 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7929 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7944 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8092 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7888 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7965 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7961 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7942 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7970 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7928 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8182 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7718 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7944 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7971 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7794 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7787 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.8118 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8072 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.8020 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7905 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7759 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7847 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7835 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7757 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8047 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.8081 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.7966 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8066 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7835 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8097 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7892 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7779 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7846 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7753 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8044 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8217 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8067 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7706 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8146 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7916 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7942 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7910 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8179 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7922 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7681 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7853 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7815 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8085 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8038 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7941 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7785 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7790 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7672 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7694 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7943 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8014 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7927 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7887 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7837 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.8140 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7648 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7832 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7858 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7860 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7823 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7610 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8222 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7950 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7803 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7801 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7928 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8050 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7885 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8040 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8090 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8172 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8125 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7937 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.8025 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7876 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7806 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7841 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7805 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7976 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7868 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7938 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7788 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.8001 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7720 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8011 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7843 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7886 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7698 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7961 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7803 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.7604 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8162 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7956 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7870 - val_loss: 0.5043 - val_accuracy: 0.7656\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8026 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7794 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7742 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7980 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7668 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7840 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7566 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7978 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7924 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8046 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7698 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7677 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.7995 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7878 - val_loss: 0.5042 - val_accuracy: 0.7656\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7954 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7786 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7831 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7633 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7754 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7979 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7943 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.7800 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7771 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7731 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7825 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7502 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7850 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7889 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.7706 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7833 - val_loss: 0.5041 - val_accuracy: 0.7656\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7849 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7798 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8069 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.7864 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7714 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7896 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7814 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7813 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8104 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7779 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7876 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8116 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7810 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8068 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7941 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7562 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8070 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7645 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8086 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7953 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7959 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7662 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7426 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7884 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7625 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7952 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7640 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7726 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8188 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7905 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7800 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7848 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7937 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7719 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7913 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7765 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4496 - accuracy: 0.7775 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7890 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7788 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7813 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7919 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7792 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7746 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7950 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7777 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7790 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7903 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7769 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7779 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7739 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7830 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7872 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7798 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7699 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7852 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8155 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7978 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7973 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7658 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8028 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.7509 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7742 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7725 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7797 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7680 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7797 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7622 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7842 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7813 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8052 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7804 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7889 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7751 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8024 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8037 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7814 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.7836 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7981 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7602 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7571 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7967 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7826 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7638 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7631 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7870 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8012 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7779 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7828 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7689 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7891 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7724 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7852 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7678 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7819 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7910 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7877 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7858 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8037 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7949 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7829 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7798 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7798 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8065 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7727 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7830 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7776 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7701 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7675 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7656 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7717 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7944 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7800 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8060 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8013 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7789 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7596 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7620 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7817 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7668 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7663 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7687 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7875 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7979 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8074 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7792 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7916 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7891 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7779 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7734 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.8013 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7618 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7905 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7942 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.7944 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7967 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7940 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7817 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7985 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7845 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8089 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8091 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7974 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7874 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7776 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7810 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8138 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7862 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.7973 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8179 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7843 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.7920 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.7875 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7825 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4008 - accuracy: 0.8027 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4208 - accuracy: 0.8003 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7661 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7733 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7672 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7828 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7665 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7687 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7912 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8111 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7686 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8066 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7905 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7907 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7760 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7853 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7592 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.7913 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7915 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.7917 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7863 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.7756 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7822 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7977 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.7896 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7813 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7791 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8025 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8053 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7862 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7747 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7866 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7704 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7678 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7846 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8046 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7860 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7844 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8137 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7697 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7840 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7640 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7894 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.7994 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7772 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7636 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7928 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7935 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.7908 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8037 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7721 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8019 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7932 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7668 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7692 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4480 - accuracy: 0.7838 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7621 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7695 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8060 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7884 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7800 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.7895 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7837 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8082 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7663 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7937 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7803 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7902 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.7700 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.7931 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7716 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7786 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7867 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7773 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4190 - accuracy: 0.8014 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7852 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7680 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7834 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7806 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7958 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7756 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7947 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7650 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.7938 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7916 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7772 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7800 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8020 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7931 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.7944 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.7875 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7843 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7934 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8112 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7870 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7698 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7800 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7536 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8084 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8100 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7616 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7783 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7939 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.7985 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7985 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7970 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8059 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.7804 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7864 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7679 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7875 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8138 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7612 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4000 - accuracy: 0.8016 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7959 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7718 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7819 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.7802 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7793 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8191 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.7887 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7845 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7757 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8015 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7647 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7965 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7800 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7601 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7935 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7691 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.7923 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8078 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7735 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7782 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7609 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7800 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7634 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7602 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7625 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7915 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7896 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7711 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7704 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7859 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.7999 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7688 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7629 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7911 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8082 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7892 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7737 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7699 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7733 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7737 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7965 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7721 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7875 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.8023 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7827 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7695 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.7973 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7997 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7743 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7869 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7664 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7821 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7789 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7919 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7826 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7827 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7965 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7988 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8070 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7987 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7885 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7865 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7927 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7786 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8071 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7867 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.7872 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7833 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.7710 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8054 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7898 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7922 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7625 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8094 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7768 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7812 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7768 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7934 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7805 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8059 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7741 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7963 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4249 - accuracy: 0.8077 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8400 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7762 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7902 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7763 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.7922 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7693 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.7981 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7844 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4155 - accuracy: 0.8063 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7941 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7940 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7816 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8027 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.8060 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7878 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8031 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7877 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7640 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.7801 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7903 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7788 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8060 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7953 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4128 - accuracy: 0.8011 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8015 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8057 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8200 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.8059 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7734 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.7903 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7883 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7898 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.8013 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7857 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8129 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8067 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.7982 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7785 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7899 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7636 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7918 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7925 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7885 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8007 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8131 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7982 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7873 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7735 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7890 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8051 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7931 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7710 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7829 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7902 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7735 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7727 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8130 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7742 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7788 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7799 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7573 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7841 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8262 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8012 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8151 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.8025 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.8013 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8048 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7992 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8175 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7728 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8121 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.7992 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7909 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3878 - accuracy: 0.8174 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7671 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8057 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8130 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7736 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7985 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8089 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.7975 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7920 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7781 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7937 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8047 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7753 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8055 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4160 - accuracy: 0.7960 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7850 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7804 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7819 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.7818 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7790 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.7782 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.7789 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7985 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7759 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7926 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7880 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7783 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8071 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7805 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7698 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7941 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7922 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.7996 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8083 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4341 - accuracy: 0.7838 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8253 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8063 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8024 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8077 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7813 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7839 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7916 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7779 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7711 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7757 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.7985 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.7973 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8036 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7638 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.7795 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8017 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7680 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7718 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7669 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7747 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4056 - accuracy: 0.8081 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.7783 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7874 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8053 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7762 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.7991 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7875 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7698 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7851 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7989 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7856 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8106 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4023 - accuracy: 0.8061 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8032 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7918 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7947 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7792 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7813 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8058 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8083 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8012 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7650 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7823 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7698 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7994 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7936 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7775 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7943 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7807 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7822 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8014 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.7883 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8069 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8074 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7961 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7698 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8101 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7755 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4139 - accuracy: 0.8109 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7942 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7931 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.7981 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7831 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7918 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7687 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.7927 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.7809 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7563 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7723 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7813 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7597 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7770 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7891 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.7920 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7788 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7840 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8107 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.7987 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7842 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7875 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7827 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7991 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7904 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7777 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7802 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7834 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7979 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.7864 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7820 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7882 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8198 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7811 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7860 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.7934 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8104 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7644 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8027 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.8019 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4186 - accuracy: 0.8011 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.7909 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7784 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7816 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7931 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7852 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8031 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8099 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.7865 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.7953 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7804 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7776 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7563 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8003 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7598 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7836 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8043 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8112 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7957 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7878 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7756 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8032 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8063 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7763 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7663 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7837 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4383 - accuracy: 0.7834 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7902 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7905 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8027 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7984 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7817 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7966 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8008 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7976 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7754 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7750 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7885 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7739 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7716 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7923 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7994 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7928 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4177 - accuracy: 0.7921 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7959 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8016 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8016 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3964 - accuracy: 0.8101 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7879 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7788 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7933 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.7921 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7754 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7904 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4170 - accuracy: 0.7890 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8024 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7656 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7988 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3836 - accuracy: 0.8179 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.7970 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.7828 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.7826 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8010 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7637 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8146 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.7794 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7966 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8082 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4488 - accuracy: 0.7831 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.7928 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7659 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7610 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7784 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7635 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7785 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7964 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7708 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7749 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8029 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8059 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8034 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.7965 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7842 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7875 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4237 - accuracy: 0.7932 - val_loss: 0.5030 - val_accuracy: 0.7708\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.7983 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7633 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7729 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7727 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7747 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.7721 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7884 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7815 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.8004 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7689 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7878 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7927 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.8043 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.7970 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7773 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7817 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7819 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7725 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7967 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4476 - accuracy: 0.7771 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.7915 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7936 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7628 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8073 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7956 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7837 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.7643 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8006 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7954 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7845 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8077 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7868 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.7997 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7803 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7920 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7861 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3955 - accuracy: 0.7934 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8011 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.7880 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8061 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8025 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7957 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8084 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7848 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8223 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7602 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7784 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8047 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8021 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8182 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7719 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.8044 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7808 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7622 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7864 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7857 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7981 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8019 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8016 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8041 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7881 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8426 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8000 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.7958 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7713 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7681 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7909 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7834 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8047 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.8001 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7944 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8068 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.7807 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7880 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7961 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7763 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.7972 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8016 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7664 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.8023 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.7683 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7817 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7709 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8142 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7807 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7924 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7596 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7603 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.8035 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8191 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7704 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7782 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.7904 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7621 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3958 - accuracy: 0.8143 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8039 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7652 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7706 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7825 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7707 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7901 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7817 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7993 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7843 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8047 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8017 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7989 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7969 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.7925 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7885 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8006 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7885 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7977 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4084 - accuracy: 0.8063 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.7814 - val_loss: 0.5037 - val_accuracy: 0.7656\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.7826 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7907 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.7993 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7688 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.7856 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8112 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7727 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.7857 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7972 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8024 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.7913 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7898 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7801 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7760 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.7952 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7923 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.7802 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7588 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8099 - val_loss: 0.5038 - val_accuracy: 0.7656\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7621 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7864 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7718 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7746 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7908 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8071 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7566 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.7948 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7771 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7771 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7892 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7635 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8232 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4221 - accuracy: 0.7870 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7813 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8038 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8004 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7779 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7676 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8036 - val_loss: 0.5039 - val_accuracy: 0.7656\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8042 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.7951 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7914 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7754 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4153 - accuracy: 0.8030 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7940 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7848 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8008 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7818 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7769 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7719 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4227 - accuracy: 0.7911 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4152 - accuracy: 0.8003 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.7854 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7920 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7855 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.7993 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7734 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7821 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7759 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7820 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7874 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7808 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7699 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.7880 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.7922 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7519 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3942 - accuracy: 0.8223 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7940 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7639 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7648 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8140 - val_loss: 0.5042 - val_accuracy: 0.7708\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.7831 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7654 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7686 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7517 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7583 - val_loss: 0.5043 - val_accuracy: 0.7708\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7971 - val_loss: 0.5044 - val_accuracy: 0.7708\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7779 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7757 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8081 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7867 - val_loss: 0.5044 - val_accuracy: 0.7656\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8044 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8074 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4225 - accuracy: 0.7803 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7982 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.7758 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7753 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8070 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7495 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7945 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7944 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7908 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7738 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3855 - accuracy: 0.8395 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.7906 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8037 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8118 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.7875 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.7919 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7658 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8107 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7980 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8006 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7732 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8015 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4338 - accuracy: 0.7783 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7840 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4032 - accuracy: 0.8042 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7798 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7724 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7874 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7642 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7858 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7824 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7738 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8059 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.7875 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.7786 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7792 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7600 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8132 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7460 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7876 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7877 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7758 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.7807 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7855 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7699 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7788 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.7948 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4486 - accuracy: 0.7877 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8079 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8074 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3891 - accuracy: 0.8172 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8057 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7974 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8076 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7699 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8162 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7793 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3961 - accuracy: 0.8073 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7933 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7641 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8158 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.7729 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7916 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4000 - accuracy: 0.8043 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.7940 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7710 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7829 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7786 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7931 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7850 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7821 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7669 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7917 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7770 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.7987 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.7805 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.7969 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.7966 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8031 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.7784 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7791 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7893 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.7889 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7826 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7955 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8048 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.7868 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7664 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7792 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7797 - val_loss: 0.5046 - val_accuracy: 0.7656\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3953 - accuracy: 0.8092 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.7970 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7658 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7746 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4062 - accuracy: 0.8046 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7956 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7727 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7925 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7856 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3963 - accuracy: 0.8079 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7797 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7909 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8090 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7745 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7951 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7774 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7773 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7983 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7785 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7702 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8011 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.7922 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7944 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8008 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7817 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.7825 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7907 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7778 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.7957 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7705 - val_loss: 0.5047 - val_accuracy: 0.7656\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4092 - accuracy: 0.7901 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7613 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7836 - val_loss: 0.5047 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "#  Adam, SGD, RMSprop\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.766\n",
      "roc-auc is 0.819\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
